{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the code in Python, complete the following steps\n",
    "\n",
    "`python3 -m venv eeng415_hw7`\n",
    "\n",
    "`pip3 install ipykernel keras tensorflow==2.12.* pandas numpy matplotlib`\n",
    "\n",
    "There are sometimes issues with installing tensorflow (Certain versions of python are incompatible with tensorflow), but it should work on 64-bit Python 3.8.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1] # +\n",
    "x2 = [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1] # O\n",
    "x3 = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1] # <\n",
    "x4 = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1] # S\n",
    "x5 = [0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1] # psi\n",
    "x6 = [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1] # >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim =26, activation = 'relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# to build training data. \n",
    "# index of ANN_TRUTH_SET_X matches index of one-hot encoded response in ANN_TRUTH_SET_Y\n",
    "ANN_TRUTH_SET_X = [x1, x2, x3, x4, x5, x6]\n",
    "ANN_TRUTH_SET_Y = [\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "LEN_OF_TRAINING_DATA = 1000\n",
    "\n",
    "X = [x1, x2, x3, x4, x5, x6]\n",
    "Y = [\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "for i in range(LEN_OF_TRAINING_DATA):\n",
    "    # choose random integer to add that index of ANN_TRUTH_SET to training data\n",
    "    rand_int = random.randint(0, 5) \n",
    "    X.append(ANN_TRUTH_SET_X[rand_int])\n",
    "    Y.append(ANN_TRUTH_SET_Y[rand_int])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "#scores = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "101/101 [==============================] - 0s 875us/step - loss: 0.1149 - accuracy: 0.5060\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 830us/step - loss: 0.0665 - accuracy: 0.8121\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 820us/step - loss: 0.0339 - accuracy: 0.9404\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 829us/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 811us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 777us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 783us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 772us/step - loss: 9.7357e-04 - accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 760us/step - loss: 7.0521e-04 - accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 775us/step - loss: 5.3611e-04 - accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 740us/step - loss: 4.2214e-04 - accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 771us/step - loss: 3.4059e-04 - accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 796us/step - loss: 2.8076e-04 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 841us/step - loss: 2.3528e-04 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 874us/step - loss: 1.9984e-04 - accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 819us/step - loss: 1.7161e-04 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 816us/step - loss: 1.4886e-04 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 753us/step - loss: 1.3015e-04 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 1.1446e-04 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.0135e-04 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 773us/step - loss: 9.0240e-05 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 772us/step - loss: 8.0753e-05 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 774us/step - loss: 7.2562e-05 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 732us/step - loss: 6.5438e-05 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 721us/step - loss: 5.9246e-05 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 805us/step - loss: 5.3839e-05 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 768us/step - loss: 4.9026e-05 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 729us/step - loss: 4.4780e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 712us/step - loss: 4.0980e-05 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 718us/step - loss: 3.7584e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 703us/step - loss: 3.4547e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 782us/step - loss: 3.1812e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 758us/step - loss: 2.9333e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 794us/step - loss: 2.7097e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 792us/step - loss: 2.5068e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 868us/step - loss: 2.3233e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 839us/step - loss: 2.1563e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 785us/step - loss: 2.0021e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 868us/step - loss: 1.8612e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 813us/step - loss: 1.7325e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 803us/step - loss: 1.6141e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 812us/step - loss: 1.5052e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 787us/step - loss: 1.4045e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 790us/step - loss: 1.3116e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 778us/step - loss: 1.2260e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 751us/step - loss: 1.1462e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 736us/step - loss: 1.0727e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 763us/step - loss: 1.0046e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 758us/step - loss: 9.4108e-06 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 791us/step - loss: 8.8238e-06 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 768us/step - loss: 8.2764e-06 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 764us/step - loss: 7.7644e-06 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 747us/step - loss: 7.2883e-06 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 6.8461e-06 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 730us/step - loss: 6.4351e-06 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 739us/step - loss: 6.0471e-06 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 726us/step - loss: 5.6830e-06 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 758us/step - loss: 5.3462e-06 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 720us/step - loss: 5.0313e-06 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 732us/step - loss: 4.7329e-06 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 754us/step - loss: 4.4555e-06 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 758us/step - loss: 4.1956e-06 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 785us/step - loss: 3.9515e-06 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 770us/step - loss: 3.7230e-06 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 846us/step - loss: 3.5093e-06 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 746us/step - loss: 3.3078e-06 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 754us/step - loss: 3.1177e-06 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 731us/step - loss: 2.9409e-06 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 2.7743e-06 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 2.6169e-06 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 743us/step - loss: 2.4689e-06 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 721us/step - loss: 2.3290e-06 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 732us/step - loss: 2.1991e-06 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 759us/step - loss: 2.0754e-06 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 761us/step - loss: 1.9593e-06 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 751us/step - loss: 1.8502e-06 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 731us/step - loss: 1.7475e-06 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 735us/step - loss: 1.6505e-06 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 741us/step - loss: 1.5591e-06 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 992us/step - loss: 1.4731e-06 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "101/101 [==============================] - 0s 709us/step - loss: 1.3917e-06 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 734us/step - loss: 1.3153e-06 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 718us/step - loss: 1.2429e-06 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 726us/step - loss: 1.1748e-06 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 726us/step - loss: 1.1106e-06 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 739us/step - loss: 1.0498e-06 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 748us/step - loss: 9.9248e-07 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 734us/step - loss: 9.3837e-07 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 737us/step - loss: 8.8744e-07 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 730us/step - loss: 8.3911e-07 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 727us/step - loss: 7.9365e-07 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 729us/step - loss: 7.5075e-07 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 723us/step - loss: 7.1012e-07 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 738us/step - loss: 6.7174e-07 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 711us/step - loss: 6.3549e-07 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 808us/step - loss: 6.0125e-07 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 746us/step - loss: 5.6891e-07 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 727us/step - loss: 5.3830e-07 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 740us/step - loss: 5.0933e-07 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 747us/step - loss: 4.8202e-07 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 739us/step - loss: 4.5616e-07 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 754us/step - loss: 4.3173e-07 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 741us/step - loss: 4.0872e-07 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 728us/step - loss: 3.8688e-07 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 727us/step - loss: 3.6624e-07 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 726us/step - loss: 3.4665e-07 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 736us/step - loss: 3.2816e-07 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 726us/step - loss: 3.1068e-07 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 822us/step - loss: 2.9414e-07 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 807us/step - loss: 2.7857e-07 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 908us/step - loss: 2.6376e-07 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 795us/step - loss: 2.4982e-07 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 813us/step - loss: 2.3662e-07 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 798us/step - loss: 2.2402e-07 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 805us/step - loss: 2.1217e-07 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "101/101 [==============================] - 0s 767us/step - loss: 2.0098e-07 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 811us/step - loss: 1.9038e-07 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 771us/step - loss: 1.8029e-07 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 1.7080e-07 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 739us/step - loss: 1.6180e-07 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 728us/step - loss: 1.5331e-07 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 743us/step - loss: 1.4525e-07 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 736us/step - loss: 1.3763e-07 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 742us/step - loss: 1.3040e-07 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 735us/step - loss: 1.2356e-07 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 737us/step - loss: 1.1708e-07 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 811us/step - loss: 1.1096e-07 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 750us/step - loss: 1.0515e-07 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 738us/step - loss: 9.9691e-08 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 721us/step - loss: 9.4503e-08 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 732us/step - loss: 8.9552e-08 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 738us/step - loss: 8.4905e-08 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 756us/step - loss: 8.0491e-08 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 928us/step - loss: 7.6308e-08 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 738us/step - loss: 7.2342e-08 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 734us/step - loss: 6.8600e-08 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 756us/step - loss: 6.5061e-08 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 736us/step - loss: 6.1687e-08 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 760us/step - loss: 5.8509e-08 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 744us/step - loss: 5.5506e-08 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 745us/step - loss: 5.2647e-08 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 800us/step - loss: 4.9941e-08 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 719us/step - loss: 4.7381e-08 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 732us/step - loss: 4.4949e-08 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 771us/step - loss: 4.2657e-08 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 753us/step - loss: 4.0479e-08 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 740us/step - loss: 3.8416e-08 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 751us/step - loss: 3.6460e-08 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 896us/step - loss: 3.4617e-08 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 752us/step - loss: 3.2864e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs = 150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAL0lEQVR4nO3de3hUxeHG8XeTTTZALnIzIRhCoCpgvJFUChqxLQbBolRbEQVU1BovhRC1gGBRVCLYKkUMCEIVq4CteP1FSlCIKKlouEiFVlsuQUzEoE24SG57fn/ALqwJkITsmU32+3mefWBn55wzk1j27ZyZOQ7LsiwBAAAEkRDTDQAAALAbAQgAAAQdAhAAAAg6BCAAABB0CEAAACDoEIAAAEDQIQABAICgQwACAABBhwAEAACCDgEIwAk5HI56vVavXn1K13nooYfkcDgadezq1aubpA2ncm2Hw6Hnn3++zjo/+9nP5HA41LVrV5/yAwcOaPr06Tr//PMVHR2tqKgode/eXdddd53y8/PrvEZdr+NdF8DxOU03AEBgKygo8Hn/yCOPaNWqVXrvvfd8ynv16nVK17ntttt0xRVXNOrY3r17q6Cg4JTbcCqioqK0YMEC3XzzzT7l27dv1+rVqxUdHe1TXlNTo/T0dG3evFn333+/LrroIknSF198obfeektr1qxR//79fY6ZNm2afvrTn9a6dvfu3Zu2M0AQIAABOKGf/OQnPu87duyokJCQWuU/dPDgQbVu3bre1znjjDN0xhlnNKqN0dHRJ22Pvw0bNkzPPfecvvjiC5155pne8oULF6pz584699xztWXLFm/5+++/r7Vr12rhwoW65ZZbvOUDBw7UPffcI7fbXesaZ555pvF+Ai0Ft8AAnLLLLrtMycnJev/999WvXz+1bt1ao0ePliQtXbpU6enp6tSpk1q1aqWePXtqwoQJOnDggM856roF1rVrV/3iF7/Q8uXL1bt3b7Vq1Uo9evTQwoULferVdQvs5ptvVmRkpP7zn/9o8ODBioyMVEJCgu69915VVFT4HP/ll1/qV7/6laKionTaaafpxhtv1Mcff9yg20uXX365EhISfNrmdrv1wgsv6KabblJIiO8/t3v37pUkderUqc7z/bA+gKbF/8IANIni4mKNGDFCN9xwg3Jzc3XXXXdJOnxLZ/DgwVqwYIGWL1+uzMxMvfLKKxoyZEi9zrtp0ybde++9GjdunN544w2dd955uvXWW/X++++f9NiqqipdddVV+vnPf6433nhDo0eP1lNPPaXp06d76xw4cEA//elPtWrVKk2fPl2vvPKKYmNjNWzYsAb1PyQkRDfffLMWLVqkmpoaSdKKFSv05Zdf+ozweKSmpiosLExjx47VSy+9pOLi4pNew+12q7q6utYLQCNYANAAN910k9WmTRufsv79+1uSrHffffeEx7rdbquqqsrKz8+3JFmbNm3yfjZlyhTrh/8kJSYmWhEREdbOnTu9Zd9//73Vrl0764477vCWrVq1ypJkrVq1yqedkqxXXnnF55yDBw+2zj77bO/7Z555xpJkvfPOOz717rjjDkuS9ec///mEffJc+69//au1bds2y+FwWG+//bZlWZb161//2rrsssssy7KsK6+80kpMTPQ5dsGCBVZkZKQlyZJkderUyRo1apT1/vvv13mN47127dp1wjYCqI0RIABNom3btvrZz35Wq3zbtm264YYbFBcXp9DQUIWFhXkn927duvWk573gggvUpUsX7/uIiAidddZZ2rlz50mPdTgctUaazjvvPJ9j8/PzFRUVVWsC9vDhw096/h9KSkrSZZddpoULF2rv3r3eUafjGT16tL788ku9/PLLGjNmjBISEvSXv/xF/fv31xNPPFGr/vTp0/Xxxx/XesXGxja4rUCwYxI0gCZR11yW/fv3Ky0tTREREXr00Ud11llnqXXr1tq1a5euueYaff/99yc9b/v27WuVuVyueh3bunVrRURE1Dr20KFD3vd79+6tM0A0NlTceuutuuWWW/Tkk0+qVatW+tWvfnXC+jExMRo+fLg3cH322WcaMGCAJk2apNtvv12nnXaat263bt2UmpraqHYB8MUIEIAmUdcePu+9956++uorLVy4ULfddpsuvfRSpaamKioqykAL69a+fXt9/fXXtcpLSkoadb5rrrlGrVu31uOPP67rr79erVq1atDx55xzjq6//npVVVXp888/b1QbAJwcAQiA33hCkcvl8il/9tlnTTSnTv3799e+ffv0zjvv+JQvWbKkUedr1aqVfv/732vIkCG68847j1tv7969qqysrPOzf/3rX5Kk+Pj4RrUBwMlxCwyA3/Tr109t27ZVRkaGpkyZorCwML300kvatGmT6aZ53XTTTXrqqac0YsQIPfroo/rRj36kd955R3//+98lNW45elZWlrKysk5YZ9WqVRo7dqxuvPFG9evXT+3bt9eePXu0ePFiLV++XKNGjaq1L9IXX3yhf/zjH7XOdSp7KAHBigAEwG/at2+v//u//9O9996rESNGqE2bNrr66qu1dOlS9e7d23TzJElt2rTRe++9p8zMTP3ud7+Tw+FQenq6cnJyNHjwYJ85OE3pJz/5iUaPHq1Vq1bpxRdfVGlpqVq1aqVevXrp6aefrnP06IEHHqjzXJMmTdKjjz7ql3YCLZXDsizLdCMAINBMmzZNkydPVlFREaMrQAvECBCAoDd79mxJUo8ePVRVVaX33ntPs2bN0ogRIwg/QAtFAAIQ9Fq3bq2nnnpKO3bsUEVFhbp06aLx48dr8uTJppsGwE+4BQYAAIIOy+ABAEDQIQABAICgYzwA5eTkKCkpSREREUpJSdGaNWuOW7e4uFg33HCDzj77bIWEhCgzM7NWnfnz5ystLU1t27ZV27ZtNWDAAK1bt86PPQAAAM2N0UnQS5cuVWZmpnJycnTxxRfr2Wef1aBBg7Rlyxafhx96VFRUqGPHjpo0aZKeeuqpOs+5evVqDR8+XP369VNERIRmzJih9PR0ffbZZ+rcuXO92uV2u/XVV18pKiqqzu39AQBA4LEsS/v27VN8fPzJNzE1+Sj6iy66yMrIyPAp69GjhzVhwoSTHtu/f39r7NixJ61XXV1tRUVFWS+88EK927Vr1y5LEi9evHjx4sWrGb527dp10u96YyNAlZWVKiws1IQJE3zK09PTtXbt2ia7zsGDB1VVVaV27dodt05FRYUqKiq8760jC+N27dql6OjoJmsLAADwn/LyciUkJNTrgcvGAlBpaalqamoUGxvrUx4bG9vopzDXZcKECercubMGDBhw3DrZ2dl6+OGHa5VHR0cTgAAAaGbqM33F+CToHzbSsqwmm3czY8YMLV68WMuWLVNERMRx602cOFFlZWXe165du5rk+gAAIDAZGwHq0KGDQkNDa4327Nmzp9aoUGP84Q9/0LRp07Ry5Uqdd955J6zrcrnkcrlO+ZoAAKB5MDYCFB4erpSUFOXl5fmU5+XlqV+/fqd07ieeeEKPPPKIli9frtTU1FM6FwAAaHmMLoPPysrSyJEjlZqaqr59+2revHkqKipSRkaGpMO3pnbv3q1FixZ5j9m4caMkaf/+/frmm2+0ceNGhYeHq1evXpIO3/Z68MEH9fLLL6tr167eEabIyEhFRkba20EAABCQjD8LLCcnRzNmzFBxcbGSk5P11FNP6dJLL5Uk3XzzzdqxY4dWr17trV/X/KDExETt2LFDktS1a1ft3LmzVp0pU6booYceqlebysvLFRMTo7KyMiZBAwDQTDTk+9t4AApEBCAAAJqfhnx/G18FBgAAYDcCEAAACDoEIAAAEHQIQAAAIOgQgAAAQNAhAAEAgKBjdCPEYFNRXaPS/ZVySIo/rZXp5gAAELQYAbLR5i/LdPHj7+mG+f8w3RQAAIIaAchGztDDP+6qGvaeBADAJAKQjZwhhx/jUVXjNtwSAACCGwHIRuFOzwgQAQgAAJMIQDbyjABVcwsMAACjCEA2CjsyB6iSESAAAIwiANnIE4Cq3YwAAQBgEgHIRmGhh2+B1bgtuQlBAAAYQwCykWcZvCRVubkNBgCAKQQgG4UfE4CYCA0AgDkEIBs5j9wCk1gKDwCASQQgG3mWwUvsBg0AgEkEIBs5HA7vRGhGgAAAMIcAZDPvUnhGgAAAMIYAZDPPbTA2QwQAwBwCkM08zwOrZhk8AADGEIBs5gw58kDUam6BAQBgCgHIZmHOI5OgGQECAMAYApDNwrwjQAQgAABMIQDZjAeiAgBgHgHIZp7doFkFBgCAOQQgm7EPEAAA5hGAbMZO0AAAmEcAspl3GTwBCAAAYwhANgtzegIQt8AAADCFAGSzsCOPwqhmBAgAAGMIQDbzTIKuYhk8AADGEIBs5lkGz0aIAACYQwCyWXgoD0MFAMA0ApDNvCNATIIGAMAYApDNvHOAmAQNAIAxBCCbEYAAADCPAGQzz07QPAoDAABzCEA2cx4ZAeJhqAAAmEMAshkPQwUAwDwCkM08O0EzBwgAAHMIQDbjWWAAAJhHALKZkxEgAACMIwDZLNzJTtAAAJhGALKZM+TIKrBqboEBAGCK8QCUk5OjpKQkRUREKCUlRWvWrDlu3eLiYt1www06++yzFRISoszMzDrrvfrqq+rVq5dcLpd69eql1157zU+tbzjvPkCMAAEAYIzRALR06VJlZmZq0qRJ2rBhg9LS0jRo0CAVFRXVWb+iokIdO3bUpEmTdP7559dZp6CgQMOGDdPIkSO1adMmjRw5Utddd50++ugjf3al3tgJGgAA8xyWZRm7F9OnTx/17t1bc+bM8Zb17NlTQ4cOVXZ29gmPveyyy3TBBRdo5syZPuXDhg1TeXm53nnnHW/ZFVdcobZt22rx4sX1ald5ebliYmJUVlam6Ojo+neoHv7v02Ld/fJ6XZTUTq/c0bdJzw0AQDBryPe3sRGgyspKFRYWKj093ac8PT1da9eubfR5CwoKap1z4MCBJzxnRUWFysvLfV7+4vQ+CoMRIAAATDEWgEpLS1VTU6PY2Fif8tjYWJWUlDT6vCUlJQ0+Z3Z2tmJiYryvhISERl//ZDxzgNgHCAAAc4xPgnY4HD7vLcuqVebvc06cOFFlZWXe165du07p+ifCHCAAAMxzmrpwhw4dFBoaWmtkZs+ePbVGcBoiLi6uwed0uVxyuVyNvmZDeJbBE4AAADDH2AhQeHi4UlJSlJeX51Oel5enfv36Nfq8ffv2rXXOFStWnNI5m1K407MMnltgAACYYmwESJKysrI0cuRIpaamqm/fvpo3b56KioqUkZEh6fCtqd27d2vRokXeYzZu3ChJ2r9/v7755htt3LhR4eHh6tWrlyRp7NixuvTSSzV9+nRdffXVeuONN7Ry5Up98MEHtvevLt4RoGpGgAAAMMVoABo2bJj27t2rqVOnqri4WMnJycrNzVViYqKkwxsf/nBPoAsvvND798LCQr388stKTEzUjh07JEn9+vXTkiVLNHnyZD344IPq3r27li5dqj59+tjWrxPxzgFiBAgAAGOM7gMUqPy5D9AXX+/T5U+9r9Nah2nj79NPfgAAAKiXZrEPULDyjABVswweAABjCEA282yEWMkqMAAAjCEA2SzcOwJEAAIAwBQCkM2cRwKQ25JqmAgNAIARBCCbeR6FIbEZIgAAphCAbOaZBC0RgAAAMIUAZLNjAxArwQAAMIMAZLPQEIc8z2WtcjMCBACACQQgA44+EZ4RIAAATCAAGRAWcuSBqMwBAgDACAKQAWFOzwgQAQgAABMIQAZ4nwjPLTAAAIwgABkQfmQvIEaAAAAwgwBkgJNJ0AAAGEUAMsDJCBAAAEYRgAw4+kBURoAAADCBAGQAI0AAAJhFADLg6EaIBCAAAEwgABkQxjJ4AACMIgAZEOY8shM0zwIDAMAIApABno0QK6sJQAAAmEAAMsAzB6jazS0wAABMIAAZEMYqMAAAjCIAGRDGTtAAABhFADLAsw9QNSNAAAAYQQAyIJx9gAAAMIoAZMDRnaC5BQYAgAkEIAPYCRoAALMIQAawDB4AALMIQAZ4lsGzESIAAGYQgAzw7ATNozAAADCDAGRAuPPIHKBqboEBAGACAcgAZ8iRVWCMAAEAYAQByAAnO0EDAGAUAciAcHaCBgDAKAKQAU72AQIAwCgCkAE8DBUAALMIQAaEeR+FwQgQAAAmEIAM8O4EzQgQAABGEIAM8CyDr2QECAAAIwhABoQ52QkaAACTCEAGhIVwCwwAAJMIQAZ4H4bKLTAAAIwgABngZBI0AABGEYAMCGcjRAAAjCIAGeD07gPECBAAACYQgAwIYwQIAACjCEAGhPEwVAAAjDIegHJycpSUlKSIiAilpKRozZo1J6yfn5+vlJQURUREqFu3bpo7d26tOjNnztTZZ5+tVq1aKSEhQePGjdOhQ4f81YUG41lgAACYZTQALV26VJmZmZo0aZI2bNigtLQ0DRo0SEVFRXXW3759uwYPHqy0tDRt2LBBDzzwgMaMGaNXX33VW+ell17ShAkTNGXKFG3dulULFizQ0qVLNXHiRLu6dVLeOUButyyLEAQAgN0clsFv4D59+qh3796aM2eOt6xnz54aOnSosrOza9UfP3683nzzTW3dutVblpGRoU2bNqmgoECSdM8992jr1q169913vXXuvfderVu37qSjSx7l5eWKiYlRWVmZoqOjG9u94/rfwUpdMDVPkvSfxwZ5l8UDAIDGa8j3t7Fv3srKShUWFio9Pd2nPD09XWvXrq3zmIKCglr1Bw4cqE8++URVVVWSpEsuuUSFhYVat26dJGnbtm3Kzc3VlVdeedy2VFRUqLy83OflT8cGnmo3I0AAANjNaerCpaWlqqmpUWxsrE95bGysSkpK6jympKSkzvrV1dUqLS1Vp06ddP311+ubb77RJZdcIsuyVF1drTvvvFMTJkw4bluys7P18MMPn3qn6skzCVo6vBt0RFiobdcGAAABMAna4XD4vLcsq1bZyeofW7569Wo99thjysnJ0fr167Vs2TK9/fbbeuSRR457zokTJ6qsrMz72rVrV2O7Uy+eZ4FJ7AYNAIAJxkaAOnTooNDQ0FqjPXv27Kk1yuMRFxdXZ32n06n27dtLkh588EGNHDlSt912myTp3HPP1YEDB/Sb3/xGkyZNUkhI7czncrnkcrmaolv1EhLiUIhDclvsBQQAgAnGRoDCw8OVkpKivLw8n/K8vDz169evzmP69u1bq/6KFSuUmpqqsLAwSdLBgwdrhZzQ0FBZlhVQK67YDBEAAHOM3gLLysrSc889p4ULF2rr1q0aN26cioqKlJGRIenwralRo0Z562dkZGjnzp3KysrS1q1btXDhQi1YsED33Xeft86QIUM0Z84cLVmyRNu3b1deXp4efPBBXXXVVQoNDZy5NuwFBACAOcZugUnSsGHDtHfvXk2dOlXFxcVKTk5Wbm6uEhMTJUnFxcU+ewIlJSUpNzdX48aN0zPPPKP4+HjNmjVL1157rbfO5MmT5XA4NHnyZO3evVsdO3bUkCFD9Nhjj9nevxNhN2gAAMwxug9QoPL3PkCS9OPHVuqbfRXKHZOmXvH+uQYAAMGkWewDFOzCmQMEAIAxBCBDPI/DqHYTgAAAsBsByBDPJOjKau5AAgBgNwKQIc4QRoAAADCFAGRIuJM5QAAAmEIAMsQzAsQ+QAAA2I8AZAg7QQMAYA4ByBBPAOJhqAAA2I8AZIhnJ+hKRoAAALAdAcgQJyNAAAAYQwAyhJ2gAQAwhwBkiGcnaAIQAAD2IwAZcnQVGLfAAACwGwHIEM8k6GpGgAAAsB0ByBDvCJCbESAAAOxGADLEGcIkaAAATCEAGcItMAAAzCEAGcIkaAAAzCEAGcIyeAAAzCEAGcLDUAEAMIcAZMjROUDcAgMAwG4EIEM8I0A8DBUAAPsRgAzhYagAAJhDADIknEnQAAAYQwAyxLsRIjtBAwBgOwKQIWHOIwGomhEgAADsRgAyJCzkyCowNwEIAAC7EYAMOboKjFtgAADYjQBkiJNngQEAYAwByJBwdoIGAMAYApAh7AMEAIA5BCBDPI/CqGISNAAAtiMAGeKdBM0yeAAAbEcAMsTlJAABAGAKAciQiLBQSVIFAQgAANsRgAzxjAARgAAAsB8ByBCX8/AIUI3bYi8gAABsRgAyxBV29Ed/iFEgAABsRQAyxLMRoiRVVNUYbAkAAMGHAGRISIjDG4KYBwQAgL0IQAYxERoAADMIQAa5vEvhuQUGAICdCEAGeUeAqhgBAgDATgQggzwrwbgFBgCAvQhABnn2AjrEKjAAAGxFADKISdAAAJhBADLoaABiBAgAADsZD0A5OTlKSkpSRESEUlJStGbNmhPWz8/PV0pKiiIiItStWzfNnTu3Vp3//e9/uvvuu9WpUydFRESoZ8+eys3N9VcXGs27CoxJ0AAA2KpBAWjGjBn6/vvvve/ff/99VVRUeN/v27dPd911V73Pt3TpUmVmZmrSpEnasGGD0tLSNGjQIBUVFdVZf/v27Ro8eLDS0tK0YcMGPfDAAxozZoxeffVVb53Kykpdfvnl2rFjh/72t7/p3//+t+bPn6/OnTs3pKu2iOAWGAAARjgsy7LqWzk0NFTFxcU6/fTTJUnR0dHauHGjunXrJkn6+uuvFR8fr5qa+t3S6dOnj3r37q05c+Z4y3r27KmhQ4cqOzu7Vv3x48frzTff1NatW71lGRkZ2rRpkwoKCiRJc+fO1RNPPKF//etfCgsLq2/XfJSXlysmJkZlZWWKjo5u1Dnq47eLN+itTV9pypBeuuXiJL9dBwCAYNCQ7+8GjQD9MCs1IDvVUllZqcLCQqWnp/uUp6ena+3atXUeU1BQUKv+wIED9cknn6iqqkqS9Oabb6pv3766++67FRsbq+TkZE2bNu2EoayiokLl5eU+LzswCRoAADOMzQEqLS1VTU2NYmNjfcpjY2NVUlJS5zElJSV11q+urlZpaakkadu2bfrb3/6mmpoa5ebmavLkyfrjH/+oxx577Lhtyc7OVkxMjPeVkJBwir2rH08AYhk8AAD2Mj4J2uFw+Ly3LKtW2cnqH1vudrt1+umna968eUpJSdH111+vSZMm+dxm+6GJEyeqrKzM+9q1a1dju9Mgnn2AGAECAMBezoYe8NxzzykyMlKSVF1dreeff14dOnSQdHgSdH116NBBoaGhtUZ79uzZU2uUxyMuLq7O+k6nU+3bt5ckderUSWFhYQoNDfXW6dmzp0pKSlRZWanw8PBa53W5XHK5XPVue1Px7gTNKjAAAGzVoADUpUsXzZ8/3/s+Li5OL774Yq069REeHq6UlBTl5eXpl7/8pbc8Ly9PV199dZ3H9O3bV2+99ZZP2YoVK5Samuqd8HzxxRfr5ZdfltvtVkjI4YDx+eefq1OnTnWGH5PYBwgAADMaFIB27NjRpBfPysrSyJEjlZqaqr59+2revHkqKipSRkaGpMO3pnbv3q1FixZJOrzia/bs2crKytLtt9+ugoICLViwQIsXL/ae884779TTTz+tsWPH6re//a2++OILTZs2TWPGjGnStjeFiDBugQEAYEKDb4E1pWHDhmnv3r2aOnWqiouLlZycrNzcXCUmJkqSiouLffYESkpKUm5ursaNG6dnnnlG8fHxmjVrlq699lpvnYSEBK1YsULjxo3Teeedp86dO2vs2LEaP3687f07GVaBAQBgRoP2Afroo4/07bffatCgQd6yRYsWacqUKTpw4ICGDh2qp59+2sh8mqZk1z5AL39UpAde26z0XrGaNyrVb9cBACAY+G0foIceekiffvqp9/3mzZt16623asCAAZowYYLeeuutOjcwRN28y+AZAQIAwFYNCkAbN27Uz3/+c+/7JUuWqE+fPpo/f76ysrI0a9YsvfLKK03eyJbq6CowJkEDAGCnBgWg7777zmeJen5+vq644grv+x//+Me27aHTErAPEAAAZjQoAMXGxmr79u2SDj/KYv369erbt6/383379jX6+VvBiEnQAACY0aAAdMUVV2jChAlas2aNJk6cqNatWystLc37+aeffqru3bs3eSNbqqPL4LkFBgCAnRq0DP7RRx/VNddco/79+ysyMlLPP/+8z+aCCxcurPWwUhyfdwSInaABALBVgwJQx44dtWbNGpWVlSkyMtLncROS9Ne//lVRUVFN2sCWzDsJmltgAADYqkEBaPTo0fWqt3DhwkY1Jth4J0GzCgwAAFs1KAA9//zzSkxM1IUXXqgG7J+I42ASNAAAZjQoAGVkZGjJkiXatm2bRo8erREjRqhdu3b+aluL5wlAlTVuud2WQkIchlsEAEBwaNAqsJycHBUXF2v8+PF66623lJCQoOuuu05///vfGRFqBFfY0TlUlTWMAgEAYJcGBSBJcrlcGj58uPLy8rRlyxadc845uuuuu5SYmKj9+/f7o40tVoTz6I+flWAAANinwQHoWA6HQw6HQ5Zlye3mC7yhnKEhCj1y24u9gAAAsE+DA1BFRYUWL16syy+/XGeffbY2b96s2bNnq6ioSJGRkf5oY4vmfSAqI0AAANimQZOg77rrLi1ZskRdunTRLbfcoiVLlqh9+/b+altQcDlDdLCyhhEgAABs1KAANHfuXHXp0kVJSUnKz89Xfn5+nfWWLVvWJI0LBof3AqpiKTwAADZqUAAaNWqUHA6Wajelo7tBMwIEAIBdGrwRIpoWzwMDAMB+p7QKDKfu6BPhCUAAANiFAGTY0cdhcAsMAAC7EIAM8zwQlWXwAADYhwBkGCNAAADYjwBk2NFVYIwAAQBgFwKQYZ5bYKwCAwDAPgQgw7gFBgCA/QhAhrEMHgAA+xGADDs6AkQAAgDALgQgw44+DZ5bYAAA2IUAZJgrjEnQAADYjQBkGJOgAQCwHwHIMOYAAQBgPwKQYd59gAhAAADYhgBk2NGdoLkFBgCAXQhAhrETNAAA9iMAGeYZATrECBAAALYhABnmnQTNCBAAALYhABnGJGgAAOxHADKMfYAAALAfAciwiDD2AQIAwG4EIMNYBQYAgP0IQIYduw+QZVmGWwMAQHAgABnmGQFyW1JVDQEIAAA7EIAM80yClpgIDQCAXQhAhvkGIOYBAQBgBwKQYQ6HQ+E8ER4AAFsRgALA0d2guQUGAIAdCEABICKM3aABALATASgAuLgFBgCArYwHoJycHCUlJSkiIkIpKSlas2bNCevn5+crJSVFERER6tatm+bOnXvcukuWLJHD4dDQoUObuNVNyxOADnELDAAAWxgNQEuXLlVmZqYmTZqkDRs2KC0tTYMGDVJRUVGd9bdv367BgwcrLS1NGzZs0AMPPKAxY8bo1VdfrVV3586duu+++5SWlubvbpwyHogKAIC9jAagJ598Urfeeqtuu+029ezZUzNnzlRCQoLmzJlTZ/25c+eqS5cumjlzpnr27KnbbrtNo0eP1h/+8AefejU1Nbrxxhv18MMPq1u3bnZ05ZR4d4NmBAgAAFsYC0CVlZUqLCxUenq6T3l6errWrl1b5zEFBQW16g8cOFCffPKJqqqqvGVTp05Vx44ddeutt9arLRUVFSovL/d52Yk5QAAA2MtYACotLVVNTY1iY2N9ymNjY1VSUlLnMSUlJXXWr66uVmlpqSTpww8/1IIFCzR//vx6tyU7O1sxMTHeV0JCQgN7c2q4BQYAgL2MT4J2OBw+7y3LqlV2svqe8n379mnEiBGaP3++OnToUO82TJw4UWVlZd7Xrl27GtCDUxdxzANRAQCA/zlNXbhDhw4KDQ2tNdqzZ8+eWqM8HnFxcXXWdzqdat++vT777DPt2LFDQ4YM8X7udh8eVXE6nfr3v/+t7t271zqvy+WSy+U61S41mncEqIoRIAAA7GBsBCg8PFwpKSnKy8vzKc/Ly1O/fv3qPKZv37616q9YsUKpqakKCwtTjx49tHnzZm3cuNH7uuqqq/TTn/5UGzdutP3WVn15l8EzAgQAgC2MjQBJUlZWlkaOHKnU1FT17dtX8+bNU1FRkTIyMiQdvjW1e/duLVq0SJKUkZGh2bNnKysrS7fffrsKCgq0YMECLV68WJIUERGh5ORkn2ucdtppklSrPJAcXQXGCBAAAHYwGoCGDRumvXv3aurUqSouLlZycrJyc3OVmJgoSSouLvbZEygpKUm5ubkaN26cnnnmGcXHx2vWrFm69tprTXWhSTAJGgAAezkszyxieJWXlysmJkZlZWWKjo72+/VmLP+Xclb/V7dc3FVThpzj9+sBANASNeT72/gqMDACBACA3QhAASCCOUAAANiKABQAWAUGAIC9CEABwBXGPkAAANiJABQAjj4LjBEgAADsQAAKAEyCBgDAXgSgAMDT4AEAsBcBKAAc3QmaW2AAANiBABQAIo5Mgq5kBAgAAFsQgAKAdxk8I0AAANiCABQAPJOgDzECBACALQhAAaCN63AAOlBRbbglAAAEBwJQAIhyhUk6vAqMeUAAAPgfASgAeEaAJEaBAACwAwEoADhDQ9TqyEqw/QQgAAD8jgAUICIjnJKkfYcIQAAA+BsBKEBEuTwBqMpwSwAAaPkIQAHCMwLELTAAAPyPABQgIl0EIAAA7EIAChCRLuYAAQBgFwJQgIiKOLwXECNAAAD4HwEoQER55gAxAgQAgN8RgAIEc4AAALAPAShAsA8QAAD2IQAFiKMjQOwDBACAvxGAAkQU+wABAGAbAlCA8I4AcQsMAAC/IwAFCPYBAgDAPgSgAOGdBM0tMAAA/I4AFCCiXEc2QmQECAAAvyMABQjPCND3VTWqrnEbbg0AAC0bAShAeOYASdKBihqDLQEAoOUjAAWIcGeIXM7Dv4597AUEAIBfEYACCHsBAQBgDwJQAGEvIAAA7EEACiAshQcAwB4EoADCCBAAAPYgAAWQyCN7AbEbNAAA/kUACiBHJ0GzCgwAAH8iAAUQboEBAGAPAlAAYRI0AAD2IAAFEEaAAACwBwEogESzESIAALYgAAWQSAIQAAC2IAAFEJbBAwBgDwJQAPHOAWIECAAAvyIABRDvPkCMAAEA4FfGA1BOTo6SkpIUERGhlJQUrVmz5oT18/PzlZKSooiICHXr1k1z5871+Xz+/PlKS0tT27Zt1bZtWw0YMEDr1q3zZxeaDCNAAADYw2gAWrp0qTIzMzVp0iRt2LBBaWlpGjRokIqKiuqsv337dg0ePFhpaWnasGGDHnjgAY0ZM0avvvqqt87q1as1fPhwrVq1SgUFBerSpYvS09O1e/duu7rVaMdOgq5xW4ZbAwBAy+WwLMvYN22fPn3Uu3dvzZkzx1vWs2dPDR06VNnZ2bXqjx8/Xm+++aa2bt3qLcvIyNCmTZtUUFBQ5zVqamrUtm1bzZ49W6NGjapXu8rLyxUTE6OysjJFR0c3sFeNd6iqRj0eXC5J+vShdEVHhNl2bQAAmruGfH8bGwGqrKxUYWGh0tPTfcrT09O1du3aOo8pKCioVX/gwIH65JNPVFVV9/OzDh48qKqqKrVr1+64bamoqFB5ebnPywSXM0RhoQ5JzAMCAMCfjAWg0tJS1dTUKDY21qc8NjZWJSUldR5TUlJSZ/3q6mqVlpbWecyECRPUuXNnDRgw4Lhtyc7OVkxMjPeVkJDQwN40DYfDwTwgAABsYHwStMPh8HlvWVatspPVr6tckmbMmKHFixdr2bJlioiIOO45J06cqLKyMu9r165dDelCk4qKYC8gAAD8zWnqwh06dFBoaGit0Z49e/bUGuXxiIuLq7O+0+lU+/btfcr/8Ic/aNq0aVq5cqXOO++8E7bF5XLJ5XI1ohdNjxEgAAD8z9gIUHh4uFJSUpSXl+dTnpeXp379+tV5TN++fWvVX7FihVJTUxUWdnTC8BNPPKFHHnlEy5cvV2pqatM33o8i2QsIAAC/M3oLLCsrS88995wWLlyorVu3aty4cSoqKlJGRoakw7emjl25lZGRoZ07dyorK0tbt27VwoULtWDBAt13333eOjNmzNDkyZO1cOFCde3aVSUlJSopKdH+/ftt719jRHlHgOqe1A0AAE6dsVtgkjRs2DDt3btXU6dOVXFxsZKTk5Wbm6vExERJUnFxsc+eQElJScrNzdW4ceP0zDPPKD4+XrNmzdK1117rrZOTk6PKykr96le/8rnWlClT9NBDD9nSr1PhGQFiDhAAAP5jdB+gQGVqHyBJmvTaZr30UZEyB5ypzAFn2XptAACas2axDxDqxhwgAAD8jwAUYDxzgLgFBgCA/xCAAgzL4AEA8D8CUICJ9GyESAACAMBvCEABxjsCdIhl8AAA+AsBKMBER3ALDAAAfyMABRhWgQEA4H8EoADjuQVWTgACAMBvCEABpmPU4Yey7q+o1sFKQhAAAP5AAAowkS6nWoeHSpK+Lq8w3BoAAFomAlCAcTgciouOkCR9XX7IcGsAAGiZCEAB6PTow7fBCEAAAPgHASgAxTICBACAXxGAApDnFlhJGXOAAADwBwJQADrdMwK0jxEgAAD8gQAUgLyToMsIQAAA+AMBKADFeiZBMwIEAIBfEIAC0NFJ0BWyLMtwawAAaHkIQAHIswy+stqt/x3kqfAAADQ1AlAAcjlD1a5NuCSphKXwAAA0OQJQgDo9is0QAQDwFwJQgIqLYTNEAAD8hQAUoGKjjk6EBgAATYsAFKBij4wAMQcIAICmRwAKUJ69gPYQgAAAaHIEoAAVF80tMAAA/IUAFKA8myFyCwwAgKZHAApQngBUur9C1TVuw60BAKBlIQAFqPZtwuUMcciypG/2cxsMAICmRAAKUCEhjmM2QyQAAQDQlAhAAex0zzygMuYBAQDQlAhAAcyzEmzPPgIQAABNiQAUwDx7ATECBABA0yIABbDYGPYCAgDAHwhAAezo88AYAQIAoCkRgAIYT4QHAMA/CEABzDMHqLjsEJshAgDQhAhAASyxfRu1bR2m/RXVWvOfUtPNAQCgxSAABbCw0BBdfUFnSdLfPvnScGsAAGg5CEAB7tepZ0iS8rZ8re8OVBpuDQAALQMBKMCdEx+jXp2iVVnj1hsbd5tuDgAALQIBqBnwjAL9tZDbYAAANAUCUDMw9ILOCg8N0WdflWvLV+WmmwMAQLNHAGoG2rYJ14Bep0uS/lq4y3BrAABo/ghAzcSvUxIkHV4NtvnLMsOtAQCgeSMANRNpZ3ZQ7y6naV9FtW6Y/w+t2/6t6SYBANBsEYCaCWdoiBbd2kd9ktppX0W1Ri38SO/962vTzQIAoFkiADUjkS6nnr/lIl12dkcdqnJr9POf6Lq5BVq55Wu53Zbp5gEA0GwYD0A5OTlKSkpSRESEUlJStGbNmhPWz8/PV0pKiiIiItStWzfNnTu3Vp1XX31VvXr1ksvlUq9evfTaa6/5q/m2axUeqnkjUzXyJ4kKC3Vo3Y5vdduiT3TJ9Pd0/1836fUNu7Xr24MEIgAATsBhWZaxb8qlS5dq5MiRysnJ0cUXX6xnn31Wzz33nLZs2aIuXbrUqr99+3YlJyfr9ttv1x133KEPP/xQd911lxYvXqxrr71WklRQUKC0tDQ98sgj+uUvf6nXXntNv//97/XBBx+oT58+9WpXeXm5YmJiVFZWpujo6Cbtc1MqKTukP6/drpf/UaR9FdU+n7UOD1X3jpFKbN9ap0dFqGOUSx2jXDr9yJ/t2oSrjcup1mGhCglxGOoBAABNpyHf30YDUJ8+fdS7d2/NmTPHW9azZ08NHTpU2dnZteqPHz9eb775prZu3eoty8jI0KZNm1RQUCBJGjZsmMrLy/XOO+9461xxxRVq27atFi9eXK92NZcA5PF9ZY3W7fhWa/9bqrX/2at/lZSrqqZ+v1aHQ2odFqo2LqciXU61Cg9VuDNEYaEhch35Mzw0RGHOw3+GOx1H/jz8WVhoiEIcDoWGSCEhjsN/dziO/F0KPVLmqeM48nloiEOOI5+HOhxyOA6/d+hwHcnz9yMvHf7Q4W234+jnOnys5xgdU+ZT33H0nJ5Pjr3m0c9+cE7P9U/yc2zMZ55rNf7Yxl/3REefsD8nO+sJDj75sSe6buN/BwACj8sZotOjI5r0nA35/nY26ZUboLKyUoWFhZowYYJPeXp6utauXVvnMQUFBUpPT/cpGzhwoBYsWKCqqiqFhYWpoKBA48aNq1Vn5syZx21LRUWFKioqvO/Ly5vXZoOtwkPV/6yO6n9WR0lSVY1bRd8e1Bdf79eX3x3UN/sr9M0+39d3ByvltiTLkg5U1uhAZY327Ks4yZUAAGgavbucpmV3XWzs+sYCUGlpqWpqahQbG+tTHhsbq5KSkjqPKSkpqbN+dXW1SktL1alTp+PWOd45JSk7O1sPP/xwI3sSeMJCQ9S9Y6S6d4w8bh3LsnSoyq39FdU6UFHt/fNgVY2qqt2qqrFUWVOjqmpLFTVuVVW7VXnMn5U1blVWu1VV45bbktxuSzVu6/DfLc/frWP+fqTOkfeWJdUceW95ynQ4kFlHG3lM2eFjdEwdz+Clt/xIHc9nR8/jW1arvve8R4859ponG0s7+RjqiSuc7PiTX/8k5z/p8f49/8kqmO4fmhfr5P/FoZkId5qdhmwsAHn8cLjcsqwTD6HXUf+H5Q0958SJE5WVleV9X15eroSEhJM3vhlzOBxqFR6qVuGh6hjlMt0cAABsZSwAdejQQaGhobVGZvbs2VNrBMcjLi6uzvpOp1Pt27c/YZ3jnVOSXC6XXC5CAAAAwcLY+FN4eLhSUlKUl5fnU56Xl6d+/frVeUzfvn1r1V+xYoVSU1MVFhZ2wjrHOycAAAg+Rm+BZWVlaeTIkUpNTVXfvn01b948FRUVKSMjQ9LhW1O7d+/WokWLJB1e8TV79mxlZWXp9ttvV0FBgRYsWOCzumvs2LG69NJLNX36dF199dV64403tHLlSn3wwQdG+ggAAAKP0QA0bNgw7d27V1OnTlVxcbGSk5OVm5urxMRESVJxcbGKioq89ZOSkpSbm6tx48bpmWeeUXx8vGbNmuXdA0iS+vXrpyVLlmjy5Ml68MEH1b17dy1durTeewABAICWz+g+QIGque0DBAAAGvb9bfxRGAAAAHYjAAEAgKBDAAIAAEGHAAQAAIIOAQgAAAQdAhAAAAg6BCAAABB0CEAAACDoEIAAAEDQMfoojEDl2Ry7vLzccEsAAEB9eb636/OQCwJQHfbt2ydJSkhIMNwSAADQUPv27VNMTMwJ6/AssDq43W599dVXioqKksPhOOXzlZeXKyEhQbt27QqKZ4sFW3+l4OtzsPVXCr4+B1t/peDrc0vsr2VZ2rdvn+Lj4xUScuJZPowA1SEkJERnnHFGk583Ojq6xfxHVh/B1l8p+PocbP2Vgq/PwdZfKfj63NL6e7KRHw8mQQMAgKBDAAIAAEGHAGQDl8ulKVOmyOVymW6KLYKtv1Lw9TnY+isFX5+Drb9S8PU52Pr7Q0yCBgAAQYcRIAAAEHQIQAAAIOgQgAAAQNAhAAEAgKBDAPKznJwcJSUlKSIiQikpKVqzZo3pJjWJ7Oxs/fjHP1ZUVJROP/10DR06VP/+97996liWpYceekjx8fFq1aqVLrvsMn322WeGWtz0srOz5XA4lJmZ6S1raX3evXu3RowYofbt26t169a64IILVFhY6P28pfW3urpakydPVlJSklq1aqVu3bpp6tSpcrvd3jrNvc/vv/++hgwZovj4eDkcDr3++us+n9enfxUVFfrtb3+rDh06qE2bNrrqqqv05Zdf2tiL+jtRf6uqqjR+/Hide+65atOmjeLj4zVq1Ch99dVXPudoTv2VTv47PtYdd9whh8OhmTNn+pQ3tz43BgHIj5YuXarMzExNmjRJGzZsUFpamgYNGqSioiLTTTtl+fn5uvvuu/WPf/xDeXl5qq6uVnp6ug4cOOCtM2PGDD355JOaPXu2Pv74Y8XFxenyyy/3PmutOfv44481b948nXfeeT7lLanP3333nS6++GKFhYXpnXfe0ZYtW/THP/5Rp512mrdOS+qvJE2fPl1z587V7NmztXXrVs2YMUNPPPGEnn76aW+d5t7nAwcO6Pzzz9fs2bPr/Lw+/cvMzNRrr72mJUuW6IMPPtD+/fv1i1/8QjU1NXZ1o95O1N+DBw9q/fr1evDBB7V+/XotW7ZMn3/+ua666iqfes2pv9LJf8cer7/+uj766CPFx8fX+qy59blRLPjNRRddZGVkZPiU9ejRw5owYYKhFvnPnj17LElWfn6+ZVmW5Xa7rbi4OOvxxx/31jl06JAVExNjzZ0711Qzm8S+ffusM88808rLy7P69+9vjR071rKsltfn8ePHW5dccslxP29p/bUsy7ryyiut0aNH+5Rdc8011ogRIyzLanl9lmS99tpr3vf16d///vc/KywszFqyZIm3zu7du62QkBBr+fLltrW9MX7Y37qsW7fOkmTt3LnTsqzm3V/LOn6fv/zyS6tz587WP//5TysxMdF66qmnvJ819z7XFyNAflJZWanCwkKlp6f7lKenp2vt2rWGWuU/ZWVlkqR27dpJkrZv366SkhKf/rtcLvXv37/Z9//uu+/WlVdeqQEDBviUt7Q+v/nmm0pNTdWvf/1rnX766brwwgs1f/587+ctrb+SdMkll+jdd9/V559/LknatGmTPvjgAw0ePFhSy+zzserTv8LCQlVVVfnUiY+PV3Jycov4GZSVlcnhcHhHOltif91ut0aOHKn7779f55xzTq3PW2Kf68LDUP2ktLRUNTU1io2N9SmPjY1VSUmJoVb5h2VZysrK0iWXXKLk5GRJ8vaxrv7v3LnT9jY2lSVLlmj9+vX6+OOPa33W0vq8bds2zZkzR1lZWXrggQe0bt06jRkzRi6XS6NGjWpx/ZWk8ePHq6ysTD169FBoaKhqamr02GOPafjw4ZJa3u/4h+rTv5KSEoWHh6tt27a16jT3f9sOHTqkCRMm6IYbbvA+HLQl9nf69OlyOp0aM2ZMnZ+3xD7XhQDkZw6Hw+e9ZVm1ypq7e+65R59++qk++OCDWp+1pP7v2rVLY8eO1YoVKxQREXHcei2lz263W6mpqZo2bZok6cILL9Rnn32mOXPmaNSoUd56LaW/0uF5e3/5y1/08ssv65xzztHGjRuVmZmp+Ph43XTTTd56LanPdWlM/5r7z6CqqkrXX3+93G63cnJyTlq/ufa3sLBQf/rTn7R+/foGt7+59vl4uAXmJx06dFBoaGittLxnz55a/++qOfvtb3+rN998U6tWrdIZZ5zhLY+Li5OkFtX/wsJC7dmzRykpKXI6nXI6ncrPz9esWbPkdDq9/Wopfe7UqZN69erlU9azZ0/vJP6W+Du+//77NWHCBF1//fU699xzNXLkSI0bN07Z2dmSWmafj1Wf/sXFxamyslLffffdces0N1VVVbruuuu0fft25eXleUd/pJbX3zVr1mjPnj3q0qWL99+xnTt36t5771XXrl0ltbw+Hw8ByE/Cw8OVkpKivLw8n/K8vDz169fPUKuajmVZuueee7Rs2TK99957SkpK8vk8KSlJcXFxPv2vrKxUfn5+s+3/z3/+c23evFkbN270vlJTU3XjjTdq48aN6tatW4vq88UXX1xra4PPP/9ciYmJklrm7/jgwYMKCfH9ZzE0NNS7DL4l9vlY9elfSkqKwsLCfOoUFxfrn//8Z7P8GXjCzxdffKGVK1eqffv2Pp+3tP6OHDlSn376qc+/Y/Hx8br//vv197//XVLL6/NxGZp8HRSWLFlihYWFWQsWLLC2bNliZWZmWm3atLF27Nhhummn7M4777RiYmKs1atXW8XFxd7XwYMHvXUef/xxKyYmxlq2bJm1efNma/jw4VanTp2s8vJygy1vWseuArOsltXndevWWU6n03rsscesL774wnrppZes1q1bW3/5y1+8dVpSfy3Lsm666Sarc+fO1ttvv21t377dWrZsmdWhQwfrd7/7nbdOc+/zvn37rA0bNlgbNmywJFlPPvmktWHDBu+qp/r0LyMjwzrjjDOslStXWuvXr7d+9rOfWeeff75VXV1tqlvHdaL+VlVVWVdddZV1xhlnWBs3bvT5t6yiosJ7jubUX8s6+e/4h364Csyyml+fG4MA5GfPPPOMlZiYaIWHh1u9e/f2LhNv7iTV+frzn//sreN2u60pU6ZYcXFxlsvlsi699FJr8+bN5hrtBz8MQC2tz2+99ZaVnJxsuVwuq0ePHta8efN8Pm9p/S0vL7fGjh1rdenSxYqIiLC6detmTZo0yefLsLn3edWqVXX+b/emm26yLKt+/fv++++te+65x2rXrp3VqlUr6xe/+IVVVFRkoDcnd6L+bt++/bj/lq1atcp7jubUX8s6+e/4h+oKQM2tz43hsCzLsmOkCQAAIFAwBwgAAAQdAhAAAAg6BCAAABB0CEAAACDoEIAAAEDQIQABAICgQwACAABBhwAEAHXo2rWrZs6caboZAPyEAATAuJtvvllDhw6VJF122WXKzMy07drPP/+8TjvttFrlH3/8sX7zm9/Y1g4A9nKabgAA+ENlZaXCw8MbfXzHjh2bsDUAAg0jQAACxs0336z8/Hz96U9/ksPhkMPh0I4dOyRJW7Zs0eDBgxUZGanY2FiNHDlSpaWl3mMvu+wy3XPPPcrKylKHDh10+eWXS5KefPJJnXvuuWrTpo0SEhJ01113af/+/ZKk1atX65ZbblFZWZn3eg899JCk2rfAioqKdPXVVysyMlLR0dG67rrr9PXXX3s/f+ihh3TBBRfoxRdfVNeuXRUTE6Prr79e+/bt8+8PDUCjEIAABIw//elP6tu3r26//XYVFxeruLhYCQkJKi4uVv/+/XXBBRfok08+0fLly/X111/ruuuu8zn+hRdekNPp1Icffqhnn31WkhQSEqJZs2bpn//8p1544QW99957+t3vfidJ6tevn2bOnKno6Gjv9e67775a7bIsS0OHDtW3336r/Px85eXl6b///a+GDRvmU++///2vXn/9db399tt6++23lZ+fr8cff9xPPy0Ap4JbYAACRkxMjMLDw9W6dWvFxcV5y+fMmaPevXtr2rRp3rKFCxcqISFBn3/+uc466yxJ0o9+9CPNmDHD55zHzidKSkrSI488ojvvvFM5OTkKDw9XTEyMHA6Hz/V+aOXKlfr000+1fft2JSQkSJJefPFFnXPOOfr444/14x//WJLkdrv1/PPPKyoqSpI0cuRIvfvuu3rsscdO7QcDoMkxAgQg4BUWFmrVqlWKjIz0vnr06CHp8KiLR2pqaq1jV61apcsvv1ydO3dWVFSURo0apb179+rAgQP1vv7WrVuVkJDgDT+S1KtXL5122mnaunWrt6xr167e8CNJnTp10p49exrUVwD2YAQIQMBzu90aMmSIpk+fXuuzTp06ef/epk0bn8927typwYMHKyMjQ4888ojatWunDz74QLfeequqqqrqfX3LsuRwOE5aHhYW5vO5w+GQ2+2u93UA2IcABCCghIeHq6amxqesd+/eevXVV9W1a1c5nfX/Z+uTTz5RdXW1/vjHPyok5PCA9yuvvHLS6/1Qr169VFRUpF27dnlHgbZs2aKysjL17Nmz3u0BEDi4BQYgoHTt2lUfffSRduzYodLSUrndbt1999369ttvNXz4cK1bt07btm3TihUrNHr06BOGl+7du6u6ulpPP/20tm3bphdffFFz586tdb39+/fr3XffVWlpqQ4ePFjrPAMGDNB5552nG2+8UevXr9e6des0atQo9e/fv87bbgACHwEIQEC57777FBoaql69eqljx44qKipSfHy8PvzwQ9XU1GjgwIFKTk7W2LFjFRMT4x3ZqcsFF1ygJ598UtOnT1dycrJeeuklZWdn+9Tp16+fMjIyNGzYMHXs2LHWJGrp8K2s119/XW3bttWll16qAQMGqFu3blq6dGmT9x+APRyWZVmmGwEAAGAnRoAAAEDQIQABAICgQwACAABBhwAEAACCDgEIAAAEHQIQAAAIOgQgAAAQdAhAAAAg6BCAAABA0CEAAQCAoEMAAgAAQYcABAAAgs7/A0JYC3x60R+gAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = len(history.history['loss'])\n",
    "iteration_number_for_plot = [iteration for iteration in range(1, iterations + 1)]\n",
    "\n",
    "plt.plot(\n",
    "    iteration_number_for_plot,\n",
    "    history.history['loss']\n",
    ")\n",
    "plt.title('Training MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([x1, x2, x3, x4, x5, x6])).argmax(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Noisy Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_input(array, idx):\n",
    "\n",
    "    current_val = array[idx]\n",
    "    new_val = 1 if current_val == 0 else 0\n",
    "    \n",
    "    new_array = list(array)\n",
    "    new_array[idx] = new_val\n",
    "\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following indices of the original array will be replaced in this order:\n",
      "\n",
      "[19, 9, 2, 0, 13, 15, 14, 23, 18, 11, 17, 21, 7, 8, 16, 3, 4, 20, 10, 12, 1, 6, 22, 5]\n"
     ]
    }
   ],
   "source": [
    "replacement_bits = random.sample(range(0, 24), 24)\n",
    "\n",
    "def replace_and_predict(original_array, expected_prediction, replacement_bits, model):\n",
    "    new_array = list(original_array)\n",
    "\n",
    "    for elements_replaced, idx_to_replace in enumerate(replacement_bits):\n",
    "        new_array = replace_input(new_array, idx_to_replace)\n",
    "        if model.predict(np.array([new_array])).argmax(axis=1)[0] != expected_prediction:\n",
    "            raise ValueError(f\"ANN didn't predict output correctly after {elements_replaced + 1} elements changed\\n\\nOriginal Array:\\n{original_array}\\n\\nNoisy Array:\\n{new_array}\")\n",
    "\n",
    "print(f\"The following indices of the original array will be replaced in this order:\\n\\n{replacement_bits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n\nNoisy Array:\n[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x1, \u001b[39m0\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n\nNoisy Array:\n[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x1, 0, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 11 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x2, \u001b[39m1\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 11 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x2, 1, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 11 elements changed\n\nOriginal Array:\n[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n\nNoisy Array:\n[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x3, \u001b[39m2\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 11 elements changed\n\nOriginal Array:\n[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n\nNoisy Array:\n[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x3, 2, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 11 elements changed\n\nOriginal Array:\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\nNoisy Array:\n[0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x4, \u001b[39m3\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 11 elements changed\n\nOriginal Array:\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\nNoisy Array:\n[0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x4, 3, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x5, \u001b[39m4\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x5, 4, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 5 elements changed\n\nOriginal Array:\n[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n\nNoisy Array:\n[0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x6, \u001b[39m5\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 5 elements changed\n\nOriginal Array:\n[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n\nNoisy Array:\n[0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x6, 5, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeng415",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
