{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1] # +\n",
    "x2 = [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1] # O\n",
    "x3 = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1] # <\n",
    "x4 = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1] # S\n",
    "x5 = [0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1] # psi\n",
    "x6 = [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1] # >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 19:15:27.229645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-05 19:15:30.210456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim =26, activation = 'relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# to build training data. \n",
    "# index of ANN_TRUTH_SET_X matches index of one-hot encoded response in ANN_TRUTH_SET_Y\n",
    "ANN_TRUTH_SET_X = [x1, x2, x3, x4, x5, x6]\n",
    "ANN_TRUTH_SET_Y = [\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "LEN_OF_TRAINING_DATA = 1000\n",
    "\n",
    "X = [x1, x2, x3, x4, x5, x6]\n",
    "Y = [\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "for i in range(LEN_OF_TRAINING_DATA):\n",
    "    # choose random integer to add that index of ANN_TRUTH_SET to training data\n",
    "    rand_int = random.randint(0, 5) \n",
    "    X.append(ANN_TRUTH_SET_X[rand_int])\n",
    "    Y.append(ANN_TRUTH_SET_Y[rand_int])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "#scores = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "101/101 [==============================] - 0s 749us/step - loss: 0.1093 - accuracy: 0.5775\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 879us/step - loss: 0.0666 - accuracy: 0.7097\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 912us/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 808us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 789us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 767us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 734us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 785us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 809us/step - loss: 7.3333e-04 - accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 788us/step - loss: 5.5474e-04 - accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 788us/step - loss: 4.3417e-04 - accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 777us/step - loss: 3.4786e-04 - accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 787us/step - loss: 2.8527e-04 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 790us/step - loss: 2.3790e-04 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 782us/step - loss: 2.0113e-04 - accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 761us/step - loss: 1.7184e-04 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 831us/step - loss: 1.4832e-04 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 837us/step - loss: 1.2928e-04 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 795us/step - loss: 1.1339e-04 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 764us/step - loss: 1.0016e-04 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 727us/step - loss: 8.8936e-05 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 756us/step - loss: 7.9340e-05 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 752us/step - loss: 7.1224e-05 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 709us/step - loss: 6.4033e-05 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 802us/step - loss: 5.7840e-05 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 764us/step - loss: 5.2400e-05 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 788us/step - loss: 4.7616e-05 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 795us/step - loss: 4.3419e-05 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 807us/step - loss: 3.9670e-05 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 739us/step - loss: 3.6315e-05 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 718us/step - loss: 3.3318e-05 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 706us/step - loss: 3.0646e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 777us/step - loss: 2.8221e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 711us/step - loss: 2.6025e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 708us/step - loss: 2.4053e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 868us/step - loss: 2.2237e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 718us/step - loss: 2.0603e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 734us/step - loss: 1.9115e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 721us/step - loss: 1.7738e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 741us/step - loss: 1.6482e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 735us/step - loss: 1.5333e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 699us/step - loss: 1.4278e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 696us/step - loss: 1.3310e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 1.2417e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 1.1588e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 711us/step - loss: 1.0829e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 1.0122e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 696us/step - loss: 9.4677e-06 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 8.8610e-06 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 8.2991e-06 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 7.7771e-06 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 678us/step - loss: 7.2918e-06 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 712us/step - loss: 6.8415e-06 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 741us/step - loss: 6.4184e-06 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 686us/step - loss: 6.0258e-06 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 675us/step - loss: 5.6576e-06 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 681us/step - loss: 5.3153e-06 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 683us/step - loss: 4.9952e-06 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 4.6957e-06 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 4.4168e-06 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 675us/step - loss: 4.1545e-06 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 687us/step - loss: 3.9101e-06 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 699us/step - loss: 3.6803e-06 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 696us/step - loss: 3.4658e-06 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 686us/step - loss: 3.2659e-06 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 710us/step - loss: 3.0758e-06 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 2.8978e-06 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 2.7299e-06 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 806us/step - loss: 2.5740e-06 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 808us/step - loss: 2.4269e-06 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 720us/step - loss: 2.2880e-06 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 708us/step - loss: 2.1587e-06 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 2.0362e-06 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 1.9217e-06 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 1.8127e-06 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 1.7112e-06 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 682us/step - loss: 1.6157e-06 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 681us/step - loss: 1.5252e-06 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 1.4399e-06 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 1.3596e-06 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 1.2840e-06 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 702us/step - loss: 1.2131e-06 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 1.1459e-06 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 1.0829e-06 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 712us/step - loss: 1.0232e-06 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 696us/step - loss: 9.6653e-07 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 680us/step - loss: 9.1346e-07 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 735us/step - loss: 8.6332e-07 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 706us/step - loss: 8.1620e-07 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 707us/step - loss: 7.7158e-07 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 702us/step - loss: 7.2945e-07 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 706us/step - loss: 6.8969e-07 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 797us/step - loss: 6.5215e-07 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 698us/step - loss: 6.1669e-07 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 5.8316e-07 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 701us/step - loss: 5.5154e-07 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 5.2165e-07 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 4.9350e-07 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 704us/step - loss: 4.6692e-07 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 733us/step - loss: 4.4182e-07 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 711us/step - loss: 4.1790e-07 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 3.9543e-07 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 672us/step - loss: 3.7423e-07 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 3.5425e-07 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 3.3525e-07 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 3.1714e-07 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 3.0018e-07 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 2.8413e-07 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 2.6896e-07 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 677us/step - loss: 2.5460e-07 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 2.4104e-07 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 679us/step - loss: 2.2830e-07 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 2.1605e-07 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 2.0456e-07 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 724us/step - loss: 1.9383e-07 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "101/101 [==============================] - 0s 693us/step - loss: 1.8345e-07 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 687us/step - loss: 1.7374e-07 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 1.6452e-07 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 682us/step - loss: 1.5584e-07 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 693us/step - loss: 1.4760e-07 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 700us/step - loss: 1.3983e-07 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 1.3241e-07 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 1.2546e-07 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 680us/step - loss: 1.1886e-07 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 1.1261e-07 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 1.0669e-07 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 678us/step - loss: 1.0111e-07 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 9.5814e-08 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 671us/step - loss: 9.0785e-08 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 8.6044e-08 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 708us/step - loss: 8.1559e-08 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 7.7299e-08 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 7.3303e-08 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 678us/step - loss: 6.9482e-08 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 6.5870e-08 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 6.2448e-08 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 5.9225e-08 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 824us/step - loss: 5.6161e-08 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 5.3263e-08 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 710us/step - loss: 5.0508e-08 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 4.7923e-08 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 4.5451e-08 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 4.3116e-08 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 4.0915e-08 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 693us/step - loss: 3.8834e-08 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 714us/step - loss: 3.6851e-08 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 675us/step - loss: 3.4977e-08 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 3.3212e-08 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 709us/step - loss: 3.1531e-08 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 2.9945e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs = 150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = len(history.history['loss'])\n",
    "iteration_number_for_plot = [iteration for iteration in range(1, iterations + 1)]\n",
    "\n",
    "plt.plot(\n",
    "    iteration_number_for_plot,\n",
    "    history.history['loss']\n",
    ")\n",
    "plt.title('Training MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99616265e-01, 1.25852964e-07, 8.97314894e-05, 8.23561422e-05,\n",
       "        9.06188943e-05, 1.20930265e-04],\n",
       "       [4.84949987e-06, 9.99588311e-01, 3.40894317e-08, 1.05918829e-04,\n",
       "        2.90981785e-04, 9.93651156e-06],\n",
       "       [1.59727599e-04, 6.13165554e-08, 9.99721467e-01, 3.10900396e-05,\n",
       "        2.59397893e-05, 6.18251506e-05],\n",
       "       [4.71386265e-05, 7.83156138e-05, 1.32813022e-06, 9.99763310e-01,\n",
       "        8.97034340e-07, 1.08998625e-04],\n",
       "       [9.15920464e-05, 1.75025765e-04, 2.32645270e-05, 6.16400648e-05,\n",
       "        9.99529123e-01, 1.19371311e-04],\n",
       "       [5.33244238e-05, 2.36077858e-06, 5.06722608e-05, 1.51012457e-04,\n",
       "        8.11330465e-05, 9.99661446e-01]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([x1, x2, x3, x4, x5, x6])).argmax(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Noisy Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_input(array, idx):\n",
    "\n",
    "    current_val = array[idx]\n",
    "    new_val = 1 if current_val == 0 else 0\n",
    "    \n",
    "    new_array = list(array)\n",
    "    new_array[idx] = new_val\n",
    "\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following indices of the original array will be replaced in this order:\n",
      "\n",
      "[23, 1, 22, 7, 5, 0, 14, 13, 17, 15, 2, 19, 18, 6, 11, 12, 10, 3, 16, 20, 21, 4, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "replacement_bits = random.sample(range(0, 24), 24)\n",
    "\n",
    "def replace_and_predict(original_array, expected_prediction, replacement_bits, model):\n",
    "    new_array = list(original_array)\n",
    "\n",
    "    for elements_replaced, idx_to_replace in enumerate(replacement_bits):\n",
    "        new_array = replace_input(new_array, idx_to_replace)\n",
    "        if model.predict(np.array([new_array])).argmax(axis=1)[0] != expected_prediction:\n",
    "            raise ValueError(f\"ANN didn't predict output correctly after {elements_replaced + 1} elements changed\\n\\nOriginal Array:\\n{original_array}\\n\\nNoisy Array:\\n{new_array}\")\n",
    "\n",
    "print(f\"The following indices of the original array will be replaced in this order:\\n\\n{replacement_bits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n\nNoisy Array:\n[1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x1, \u001b[39m0\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n\nNoisy Array:\n[1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x1, 0, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x2, \u001b[39m1\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x2, 1, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 7 elements changed\n\nOriginal Array:\n[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n\nNoisy Array:\n[1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x3, \u001b[39m2\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 7 elements changed\n\nOriginal Array:\n[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n\nNoisy Array:\n[1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x3, 2, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\nNoisy Array:\n[0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x4, \u001b[39m3\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\nNoisy Array:\n[0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x4, 3, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x5, \u001b[39m4\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x5, 4, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n\nNoisy Array:\n[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x6, \u001b[39m5\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 9 elements changed\n\nOriginal Array:\n[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n\nNoisy Array:\n[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x6, 5, replacement_bits, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeng415",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
