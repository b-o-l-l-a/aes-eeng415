{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1] # +\n",
    "x2 = [0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1] # O\n",
    "x3 = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1] # <\n",
    "x4 = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1] # S\n",
    "x5 = [0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1] # psi\n",
    "x6 = [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1] # >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim =26, activation = 'relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# to build training data. \n",
    "# index of ANN_TRUTH_SET_X matches index of one-hot encoded response in ANN_TRUTH_SET_Y\n",
    "ANN_TRUTH_SET_X = [x1, x2, x3, x4, x5, x6]\n",
    "ANN_TRUTH_SET_Y = [\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "LEN_OF_TRAINING_DATA = 1000\n",
    "\n",
    "X = [x1, x2, x3, x4, x5, x6]\n",
    "Y = [\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "for i in range(LEN_OF_TRAINING_DATA):\n",
    "    # choose random integer to add that index of ANN_TRUTH_SET to training data\n",
    "    rand_int = random.randint(0, 5) \n",
    "    X.append(ANN_TRUTH_SET_X[rand_int])\n",
    "    Y.append(ANN_TRUTH_SET_Y[rand_int])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "#model.fit(X, Y, epochs=150, batch_size=10)\n",
    "\n",
    "#scores = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "101/101 [==============================] - 0s 855us/step - loss: 0.1295 - accuracy: 0.1948\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 738us/step - loss: 0.0986 - accuracy: 0.7286\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 734us/step - loss: 0.0689 - accuracy: 0.8330\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 723us/step - loss: 0.0430 - accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 708us/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 698us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 713us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 704us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 706us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 699us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 740us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 724us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 705us/step - loss: 9.0123e-04 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 713us/step - loss: 7.4120e-04 - accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 6.1833e-04 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 714us/step - loss: 5.2229e-04 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 765us/step - loss: 4.4660e-04 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 739us/step - loss: 3.8552e-04 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 705us/step - loss: 3.3525e-04 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 721us/step - loss: 2.9365e-04 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 700us/step - loss: 2.5905e-04 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 2.2976e-04 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 699us/step - loss: 2.0486e-04 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 1.8320e-04 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 686us/step - loss: 1.6479e-04 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 725us/step - loss: 1.4848e-04 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 755us/step - loss: 1.3433e-04 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 772us/step - loss: 1.2192e-04 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 779us/step - loss: 1.1118e-04 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 718us/step - loss: 1.0135e-04 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 700us/step - loss: 9.2622e-05 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 8.4891e-05 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 686us/step - loss: 7.7979e-05 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 740us/step - loss: 7.1722e-05 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 771us/step - loss: 6.6069e-05 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 865us/step - loss: 6.1002e-05 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 878us/step - loss: 5.6377e-05 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 768us/step - loss: 5.2133e-05 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 778us/step - loss: 4.8283e-05 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 776us/step - loss: 4.4801e-05 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 766us/step - loss: 4.1590e-05 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 751us/step - loss: 3.8646e-05 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 761us/step - loss: 3.5956e-05 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 764us/step - loss: 3.3486e-05 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 836us/step - loss: 3.1199e-05 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 777us/step - loss: 2.9106e-05 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 759us/step - loss: 2.7160e-05 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 736us/step - loss: 2.5374e-05 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 718us/step - loss: 2.3727e-05 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 702us/step - loss: 2.2188e-05 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 680us/step - loss: 2.0741e-05 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 1.9417e-05 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 687us/step - loss: 1.8198e-05 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 1.7056e-05 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 687us/step - loss: 1.5985e-05 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 1.4988e-05 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 1.4062e-05 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 698us/step - loss: 1.3201e-05 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 682us/step - loss: 1.2397e-05 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 1.1646e-05 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 713us/step - loss: 1.0949e-05 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 706us/step - loss: 1.0291e-05 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 9.6755e-06 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 9.0996e-06 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 8.5645e-06 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 8.0609e-06 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 7.5843e-06 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 7.1420e-06 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 6.7275e-06 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 6.3372e-06 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 692us/step - loss: 5.9736e-06 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 689us/step - loss: 5.6263e-06 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 682us/step - loss: 5.3027e-06 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 701us/step - loss: 4.9984e-06 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 736us/step - loss: 4.7143e-06 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 741us/step - loss: 4.4457e-06 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 760us/step - loss: 4.1933e-06 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 804us/step - loss: 3.9564e-06 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 812us/step - loss: 3.7333e-06 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "101/101 [==============================] - 0s 772us/step - loss: 3.5215e-06 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 722us/step - loss: 3.3236e-06 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 761us/step - loss: 3.1369e-06 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 711us/step - loss: 2.9611e-06 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 754us/step - loss: 2.7958e-06 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 763us/step - loss: 2.6394e-06 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 693us/step - loss: 2.4932e-06 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 693us/step - loss: 2.3542e-06 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 702us/step - loss: 2.2242e-06 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 2.1011e-06 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 679us/step - loss: 1.9846e-06 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 708us/step - loss: 1.8754e-06 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 1.7722e-06 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 701us/step - loss: 1.6745e-06 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 721us/step - loss: 1.5823e-06 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 1.4955e-06 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 679us/step - loss: 1.4135e-06 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 1.3362e-06 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 700us/step - loss: 1.2633e-06 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 680us/step - loss: 1.1942e-06 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 1.1288e-06 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 697us/step - loss: 1.0674e-06 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 1.0096e-06 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 681us/step - loss: 9.5432e-07 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 686us/step - loss: 9.0275e-07 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 705us/step - loss: 8.5357e-07 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 679us/step - loss: 8.0787e-07 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 696us/step - loss: 7.6376e-07 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 701us/step - loss: 7.2259e-07 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 691us/step - loss: 6.8357e-07 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 695us/step - loss: 6.4650e-07 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 716us/step - loss: 6.1175e-07 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 708us/step - loss: 5.7885e-07 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 685us/step - loss: 5.4756e-07 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 701us/step - loss: 5.1822e-07 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "101/101 [==============================] - 0s 694us/step - loss: 4.9032e-07 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 693us/step - loss: 4.6399e-07 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 4.3925e-07 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 701us/step - loss: 4.1589e-07 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 749us/step - loss: 3.9338e-07 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 787us/step - loss: 3.7218e-07 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 762us/step - loss: 3.5233e-07 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 772us/step - loss: 3.3335e-07 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 791us/step - loss: 3.1563e-07 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 698us/step - loss: 2.9902e-07 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 668us/step - loss: 2.8294e-07 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 791us/step - loss: 2.6789e-07 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 755us/step - loss: 2.5361e-07 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 690us/step - loss: 2.4009e-07 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 673us/step - loss: 2.2746e-07 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 661us/step - loss: 2.1533e-07 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 688us/step - loss: 2.0388e-07 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 699us/step - loss: 1.9314e-07 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 1s 14ms/step - loss: 1.8292e-07 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 711us/step - loss: 1.7320e-07 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 684us/step - loss: 1.6405e-07 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 673us/step - loss: 1.5549e-07 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 675us/step - loss: 1.4722e-07 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 669us/step - loss: 1.3947e-07 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 677us/step - loss: 1.3210e-07 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 719us/step - loss: 1.2517e-07 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 1.1859e-07 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 679us/step - loss: 1.1237e-07 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 1.0646e-07 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 678us/step - loss: 1.0095e-07 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 679us/step - loss: 9.5618e-08 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 676us/step - loss: 9.0631e-08 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 683us/step - loss: 8.5896e-08 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 667us/step - loss: 8.1447e-08 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 674us/step - loss: 7.7219e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs = 150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = len(history.history['loss'])\n",
    "iteration_number_for_plot = [iteration for iteration in range(1, iterations + 1)]\n",
    "\n",
    "plt.plot(\n",
    "    iteration_number_for_plot,\n",
    "    history.history['loss']\n",
    ")\n",
    "plt.title('Training MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([x1])).argmax(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Noisy Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_input(array, idx):\n",
    "\n",
    "    current_val = array[idx]\n",
    "    new_val = 1 if current_val == 0 else 0\n",
    "    \n",
    "    new_array = list(array)\n",
    "    new_array[idx] = new_val\n",
    "\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following indices of the original array will be replaced in this order:\n",
      "\n",
      "[4, 10, 1, 11, 16, 23, 18, 3, 14, 17, 9, 21, 6, 19, 12, 20, 5, 2, 0, 13, 8, 7, 15, 22]\n"
     ]
    }
   ],
   "source": [
    "replacement_bits = random.sample(range(0, 24), 24)\n",
    "\n",
    "def replace_and_predict(original_array, expected_prediction, replacement_bits, model):\n",
    "    new_array = list(original_array)\n",
    "\n",
    "    for elements_replaced, idx_to_replace in enumerate(replacement_bits):\n",
    "        new_array = replace_input(new_array, idx_to_replace)\n",
    "        if model.predict(np.array([new_array])).argmax(axis=1)[0] != expected_prediction:\n",
    "            raise ValueError(f\"ANN didn't predict output correctly after {elements_replaced + 1} elements changed\\n\\nOriginal Array:\\n{original_array}\\n\\nNoisy Array:\\n{new_array}\")\n",
    "\n",
    "print(f\"The following indices of the original array will be replaced in this order:\\n\\n{replacement_bits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 12 elements changed\n\nOriginal Array:\n[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n\nNoisy Array:\n[0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x1, \u001b[39m0\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 12 elements changed\n\nOriginal Array:\n[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n\nNoisy Array:\n[0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x1, 0, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 12 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x2, \u001b[39m1\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 12 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x2, 1, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n\nNoisy Array:\n[0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x3, \u001b[39m2\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 6 elements changed\n\nOriginal Array:\n[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n\nNoisy Array:\n[0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x3, 2, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 10 elements changed\n\nOriginal Array:\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\nNoisy Array:\n[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x4, \u001b[39m3\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 10 elements changed\n\nOriginal Array:\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\nNoisy Array:\n[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x4, 3, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 4 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x5, \u001b[39m4\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 4 elements changed\n\nOriginal Array:\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\nNoisy Array:\n[0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x5, 4, replacement_bits, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ANN didn't predict output correctly after 7 elements changed\n\nOriginal Array:\n[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n\nNoisy Array:\n[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replace_and_predict(x6, \u001b[39m5\u001b[39;49m, replacement_bits, model)\n",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m, in \u001b[0;36mreplace_and_predict\u001b[0;34m(original_array, expected_prediction, replacement_bits, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m new_array \u001b[39m=\u001b[39m replace_input(new_array, idx_to_replace)\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([new_array]))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m expected_prediction:\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mANN didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt predict output correctly after \u001b[39m\u001b[39m{\u001b[39;00melements_replaced\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m elements changed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00moriginal_array\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mNoisy Array:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnew_array\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: ANN didn't predict output correctly after 7 elements changed\n\nOriginal Array:\n[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n\nNoisy Array:\n[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1]"
     ]
    }
   ],
   "source": [
    "replace_and_predict(x6, 5, replacement_bits, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeng415",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
