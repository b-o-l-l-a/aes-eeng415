{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/lrwnsf417_n1mbkjfjb9grt99pg3kq/T/ipykernel_86871/2941595942.py:18: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  educational_attainment_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"acs_educational_attainment.csv\")).drop('Unnamed: 1538', axis='columns')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "zip_tract_mapping_df = pd.read_excel(\n",
    "    os.path.join(DATA_DIR, \"ZIP_TRACT_122020 - Denver Only.xlsx\"),\n",
    "    sheet_name= \"Denver ZIP and Full Code Tracts\"\n",
    ")\n",
    "\n",
    "unique_tracts = zip_tract_mapping_df[\"TRACT\"].unique()\n",
    "unique_zips = zip_tract_mapping_df[\"ZIP\"].unique()\n",
    "\n",
    "income_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"Income - All Counties.csv\")).transpose()\n",
    "home_own_rent_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"Own v Rent - All Counties.csv\")).transpose()\n",
    "race_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"Race - All Counties.csv\")).transpose()\n",
    "educational_attainment_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"acs_educational_attainment.csv\")).drop('Unnamed: 1538', axis='columns')\n",
    "age_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"acs_age.csv\")).drop('Unnamed: 914', axis='columns')\n",
    "units_in_structure_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"acs_units_in_structure.csv\")).drop('Unnamed: 46', axis='columns')\n",
    "disability_df = pd.read_csv(os.path.join(DATA_DIR, \"raw\", \"acs_disability.csv\")).drop('Unnamed: 830', axis='columns')\n",
    "\n",
    "CENSUS_TRACT_COLNAME = 'census_tract'\n",
    "CENSUS_TRACT_NAME_COLNAME_DECENNIAL = 'Label (Grouping)'\n",
    "CENSUS_TRACT_NAME_COLNAME_ACS = 'Geographic Area Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTY_CENSUS_MAPPING = {\n",
    "    'Adams County' : '001',\n",
    "    'Arapahoe County' : '005',\n",
    "    'Denver County' : '031',\n",
    "    'Jefferson County' : '059'\n",
    "}\n",
    "\n",
    "def find_census_tract_number(tract_label):\n",
    "    \n",
    "    census_name_elems = [substr.strip() for substr in tract_label.split(\",\")]\n",
    "    try:\n",
    "        county = census_name_elems[1]\n",
    "        county_tract = COUNTY_CENSUS_MAPPING[county]\n",
    "        census_tract_name = census_name_elems[0]\n",
    "        census_tract_number = census_tract_name.lstrip(\"Census Tract \").replace(\".\", \"\")\n",
    "        census_tract_number = census_tract_number.ljust(4, \"0\").zfill(6)\n",
    "    \n",
    "        full_tract = f\"08{county_tract}{census_tract_number}\"\n",
    "    except IndexError:\n",
    "        return None\n",
    "    \n",
    "    return full_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_columns(df, col_idx = 0):\n",
    "    \n",
    "    df.columns = df.iloc[col_idx]\n",
    "    df.drop(df.index[col_idx], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_unicode_from_column_names(colname):\n",
    "\n",
    "    return str(colname).replace(u'\\xa0', u'')\n",
    "\n",
    "home_own_rent_df = assign_columns(home_own_rent_df)\n",
    "race_df = assign_columns(race_df)\n",
    "income_df = assign_columns(income_df)\n",
    "educational_attainment_df = assign_columns(educational_attainment_df)\n",
    "age_df = assign_columns(age_df)\n",
    "units_in_structure_df = assign_columns(units_in_structure_df)\n",
    "disability_df = assign_columns(disability_df)\n",
    "\n",
    "home_own_rent_df.columns = [remove_unicode_from_column_names(colname) for colname in home_own_rent_df.columns]\n",
    "race_df.columns = [remove_unicode_from_column_names(colname) for colname in race_df.columns]\n",
    "income_df.columns = [remove_unicode_from_column_names(colname) for colname in income_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_own_rent_df[CENSUS_TRACT_COLNAME] = home_own_rent_df.apply(lambda x: find_census_tract_number(x.name), axis = 1)\n",
    "race_df[CENSUS_TRACT_COLNAME] = race_df.apply(lambda x: find_census_tract_number(x.name), axis = 1)\n",
    "income_df[CENSUS_TRACT_COLNAME] = income_df.apply(lambda x: find_census_tract_number(x.name), axis = 1)\n",
    "educational_attainment_df[CENSUS_TRACT_COLNAME] = educational_attainment_df[CENSUS_TRACT_NAME_COLNAME_ACS].apply(lambda x: find_census_tract_number(x))\n",
    "age_df[CENSUS_TRACT_COLNAME] = age_df[CENSUS_TRACT_NAME_COLNAME_ACS].apply(lambda x: find_census_tract_number(x))\n",
    "units_in_structure_df[CENSUS_TRACT_COLNAME] = units_in_structure_df[CENSUS_TRACT_NAME_COLNAME_ACS].apply(lambda x: find_census_tract_number(x))\n",
    "disability_df[CENSUS_TRACT_COLNAME] = disability_df[CENSUS_TRACT_NAME_COLNAME_ACS].apply(lambda x: find_census_tract_number(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "educational_attainment_columns = [CENSUS_TRACT_COLNAME] + [col for col in educational_attainment_df.columns if col.startswith('Estimate!!Total!!AGE BY EDUCATIONAL ATTAINMENT!!Population 25 years and over')]\n",
    "removed_educational_attainment_columns = [col for col in educational_attainment_df.columns if col not in educational_attainment_columns]\n",
    "educational_attainment_df = educational_attainment_df[educational_attainment_columns]\n",
    "\n",
    "age_columns = [CENSUS_TRACT_COLNAME] + [col for col in age_df.columns if col.startswith('Estimate!!Total!!Total population!!SELECTED') or col == 'Estimate!!Total!!Total population']\n",
    "removed_age_columns = [col for col in age_df.columns if col not in age_columns]\n",
    "age_df = age_df[age_columns]\n",
    "\n",
    "units_in_structure_columns = [CENSUS_TRACT_COLNAME] + [col for col in units_in_structure_df.columns if col.startswith('Estimate!!Total:') and col not in ['Estimate!!Total:!!Mobile home', 'Estimate!!Total:!!Boat, RV, van, etc.']]\n",
    "removed_units_in_structure_columns = [col for col in units_in_structure_df.columns if col not in units_in_structure_columns]\n",
    "units_in_structure_df = units_in_structure_df[units_in_structure_columns]\n",
    "\n",
    "disability_columns = [CENSUS_TRACT_COLNAME] + ['Estimate!!Total!!Total civilian noninstitutionalized population',\n",
    "                                                'Estimate!!With a disability!!Total civilian noninstitutionalized population!!DISABILITY TYPE BY DETAILED AGE!!With a hearing difficulty', \n",
    "                                               'Estimate!!With a disability!!Total civilian noninstitutionalized population!!DISABILITY TYPE BY DETAILED AGE!!With a vision difficulty',\n",
    "                                               'Estimate!!With a disability!!Total civilian noninstitutionalized population!!DISABILITY TYPE BY DETAILED AGE!!With a cognitive difficulty',\n",
    "                                               'Estimate!!With a disability!!Total civilian noninstitutionalized population!!DISABILITY TYPE BY DETAILED AGE!!With an ambulatory difficulty',\n",
    "                                               'Estimate!!With a disability!!Total civilian noninstitutionalized population!!DISABILITY TYPE BY DETAILED AGE!!With a self-care difficulty',\n",
    "                                               'Estimate!!With a disability!!Total civilian noninstitutionalized population!!DISABILITY TYPE BY DETAILED AGE!!With an independent living difficulty'\n",
    "                                               ]\n",
    "removed_disability_columns = [col for col in disability_df.columns if col not in disability_columns]\n",
    "disability_df = disability_df[disability_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_counts_into_percentages(df, total_column, list_of_columns_to_transform):\n",
    "\n",
    "    rows_w_percentages = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        denominator = int(str(row[total_column]).replace(\",\", \"\"))\n",
    "        \n",
    "        try:\n",
    "            for col in list_of_columns_to_transform:\n",
    "                reformatted_col_name = col.lower().replace(\" \",\"_\").replace(\"$\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\",000\", \"k\").replace(\"!!\",\"_\")\n",
    "                row[f\"{reformatted_col_name}_percentage_total\"] = int(str(row[col]).replace(\",\", \"\")) / denominator\n",
    "\n",
    "            rows_w_percentages.append(row)\n",
    "\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(rows_w_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_df_w_percentages = transform_counts_into_percentages(\n",
    "    income_df,\n",
    "    'Total:',\n",
    "    [col for col in income_df.columns if col not in ['Total:', CENSUS_TRACT_COLNAME]]\n",
    ")\n",
    "\n",
    "race_df_w_percentages = transform_counts_into_percentages(\n",
    "    race_df,\n",
    "    'Population of one race:',\n",
    "    [col for col in race_df.columns if 'alone' in col]\n",
    ")\n",
    "removed_race_columns = [col for col in race_df.columns if col not in [colname for colname in race_df.columns if 'alone' in colname]]\n",
    "\n",
    "home_own_rent_df_w_percentages = transform_counts_into_percentages(\n",
    "    home_own_rent_df[['Total:', CENSUS_TRACT_COLNAME, 'Owner occupied:', 'Renter occupied:']],\n",
    "    'Total:',\n",
    "    ['Owner occupied:', 'Renter occupied:']\n",
    ")\n",
    "removed_home_own_columns = [col for col in home_own_rent_df.columns if col not in ['Total:', 'Owner occupied:', 'Renter occupied:']]\n",
    "\n",
    "educational_attainment_df_w_percentages = transform_counts_into_percentages(\n",
    "    educational_attainment_df,\n",
    "    'Estimate!!Total!!AGE BY EDUCATIONAL ATTAINMENT!!Population 25 years and over',\n",
    "    [col for col in educational_attainment_df.columns if col not in [CENSUS_TRACT_COLNAME, 'Estimate!!Total!!AGE BY EDUCATIONAL ATTAINMENT!!Population 25 years and over']]\n",
    ")\n",
    "\n",
    "age_df_w_percentages = transform_counts_into_percentages(\n",
    "    age_df,\n",
    "    'Estimate!!Total!!Total population',\n",
    "    [col for col in age_df.columns if 'SELECTED AGE CATEGORIES' in col]\n",
    ")\n",
    "\n",
    "units_in_structure_df_w_percentages = transform_counts_into_percentages(\n",
    "    units_in_structure_df,\n",
    "    'Estimate!!Total:',\n",
    "    [col for col in units_in_structure_df.columns if col.startswith('Estimate!!Total:!!')]\n",
    ")\n",
    "\n",
    "disability_df_w_percentages = transform_counts_into_percentages(\n",
    "    disability_df,\n",
    "    'Estimate!!Total!!Total civilian noninstitutionalized population',\n",
    "    [col for col in disability_df.columns if col.startswith('Estimate!!With a disability!!')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total:',\n",
       " 'Population of one race:',\n",
       " 'Population of two or more races:',\n",
       " 'Population of two races:',\n",
       " 'White; Black or African American',\n",
       " 'White; American Indian and Alaska Native',\n",
       " 'White; Asian',\n",
       " 'White; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; Some Other Race',\n",
       " 'Black or African American; American Indian and Alaska Native',\n",
       " 'Black or African American; Asian',\n",
       " 'Black or African American; Native Hawaiian and Other Pacific Islander',\n",
       " 'Black or African American; Some Other Race',\n",
       " 'American Indian and Alaska Native; Asian',\n",
       " 'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'American Indian and Alaska Native; Some Other Race',\n",
       " 'Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'Asian; Some Other Race',\n",
       " 'Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Population of three races:',\n",
       " 'White; Black or African American; American Indian and Alaska Native',\n",
       " 'White; Black or African American; Asian',\n",
       " 'White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; Black or African American; Some Other Race',\n",
       " 'White; American Indian and Alaska Native; Asian',\n",
       " 'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; American Indian and Alaska Native; Some Other Race',\n",
       " 'White; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; Asian; Some Other Race',\n",
       " 'White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Black or African American; American Indian and Alaska Native; Asian',\n",
       " 'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'Black or African American; American Indian and Alaska Native; Some Other Race',\n",
       " 'Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'Black or African American; Asian; Some Other Race',\n",
       " 'Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Population of four races:',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Asian',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
       " 'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; Black or African American; Asian; Some Other Race',\n",
       " 'White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Population of five races:',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'Population of six races:',\n",
       " 'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
       " 'census_tract']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_race_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_informative_attributes_df = pd.DataFrame(\n",
    "    removed_age_columns, columns=[\"non_informative_age_attributes\"]\n",
    ").to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes_age.csv\"))\n",
    "\n",
    "non_informative_attributes_df = pd.DataFrame(\n",
    "    removed_disability_columns, columns=[\"non_informative_comorbidities_attributes\"]\n",
    ").to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes_comorbidities.csv\"))\n",
    "\n",
    "non_informative_attributes_df = pd.DataFrame(\n",
    "    removed_educational_attainment_columns, columns=[\"non_informative_education_attainment_attributes\"]\n",
    ").to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes_educational_attainment.csv\"))\n",
    "\n",
    "non_informative_attributes_df = pd.DataFrame(\n",
    "    removed_home_own_columns, columns=[\"non_informative_home_own_attributes\"]\n",
    ").to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes_home_ownership.csv\"))\n",
    "\n",
    "non_informative_attributes_df = pd.DataFrame(\n",
    "    removed_race_columns, columns=[\"non_informative_race_attributes\"]\n",
    ").to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes_race.csv\"))\n",
    "\n",
    "non_informative_attributes_df = pd.DataFrame(\n",
    "    removed_units_in_structure_columns, columns=[\"non_informative_units_in_structure_attributes\"]\n",
    ").to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes_units_in_structure.csv\"))\n",
    "\n",
    "# non_informative_attributes_df[\"non_informative_comorbidities_attributes\"] = removed_disability_columns\n",
    "# non_informative_attributes_df[\"non_informative_educational_attainment_attributes\"] = removed_educational_attainment_columns\n",
    "# non_informative_attributes_df[\"non_informative_home_ownership_attributes\"] = removed_home_own_columns\n",
    "# non_informative_attributes_df[\"non_informative_race_attributes\"] = removed_race_columns\n",
    "# non_informative_attributes_df[\"non_informative_units_in_structure_attributes\"] = removed_units_in_structure_columns\n",
    "# non_informative_attributes_df.to_csv(os.path.join(DATA_DIR, \"processed\", \"non_informative_attributes.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_df_w_percentages.rename({'Total:':'income_total_count'}, axis=1, inplace=True)\n",
    "race_df_w_percentages.rename({'Population of one race:':'race_total_count'}, axis=1, inplace=True)\n",
    "home_own_rent_df_w_percentages.rename({'Total:':'home_own_rent_total'}, axis=1, inplace=True)\n",
    "educational_attainment_df_w_percentages.rename({'Estimate!!Total!!AGE BY EDUCATIONAL ATTAINMENT!!Population 25 years and over' : 'population_25_and_over'}, axis = 1, inplace=True)\n",
    "age_df_w_percentages.rename({'Estimate!!Total!!Total population': 'age_total_population'}, axis = 1, inplace=True)\n",
    "units_in_structure_df_w_percentages.rename({'Estimate!!Total:' : 'total_households'}, axis=1, inplace=True)\n",
    "disability_df_w_percentages.rename({'Estimate!!Total!!Total civilian noninstitutionalized population' : 'total_noninstitutionalized_population'}, axis=1, inplace=True)\n",
    "\n",
    "home_own_rent_df = home_own_rent_df_w_percentages[['home_own_rent_total', CENSUS_TRACT_COLNAME] \n",
    "                               + [col for col in home_own_rent_df_w_percentages.columns if 'percentage_total' in col]] #.to_csv(os.path.join(DATA_DIR, \"interim\", \"home_own_rent.csv\"))\n",
    "income_df = income_df_w_percentages[['income_total_count', CENSUS_TRACT_COLNAME] + \n",
    "                        [col for col in income_df_w_percentages.columns if 'percentage_total' in col]] #.to_csv(os.path.join(DATA_DIR, \"interim\", \"income.csv\"))\n",
    "race_df = race_df_w_percentages[['race_total_count', CENSUS_TRACT_COLNAME] + \n",
    "                      [col for col in race_df_w_percentages.columns if 'percentage_total' in col]] #.to_csv(os.path.join(DATA_DIR, \"interim\", \"race.csv\"))\n",
    "educational_attainment_df = educational_attainment_df_w_percentages[['population_25_and_over', CENSUS_TRACT_COLNAME] + \n",
    "                      [col for col in educational_attainment_df_w_percentages.columns if 'percentage_total' in col]]\n",
    "age_df = age_df_w_percentages[['age_total_population', CENSUS_TRACT_COLNAME] +\n",
    "                    [col for col in age_df_w_percentages.columns if 'percentage_total' in col]]\n",
    "\n",
    "units_in_structure_df = units_in_structure_df_w_percentages[['total_households', CENSUS_TRACT_COLNAME] + \n",
    "                    [col for col in units_in_structure_df_w_percentages.columns if 'percentage_total' in col]]\n",
    "\n",
    "disability_df = disability_df_w_percentages[['total_noninstitutionalized_population', CENSUS_TRACT_COLNAME] +\n",
    "                    [col for col in disability_df_w_percentages.columns if 'percentage_total' in col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_input_dataset = pd.merge(income_df, race_df_w_percentages, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "full_input_dataset = pd.merge(full_input_dataset, home_own_rent_df_w_percentages, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "full_input_dataset = pd.merge(full_input_dataset, educational_attainment_df_w_percentages, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "full_input_dataset = pd.merge(full_input_dataset, age_df_w_percentages, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "full_input_dataset = pd.merge(full_input_dataset, units_in_structure_df_w_percentages, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "full_input_dataset = pd.merge(full_input_dataset, disability_df_w_percentages, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "\n",
    "full_input_dataset.to_csv(os.path.join(DATA_DIR, \"processed\", \"full_input_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_df = pd.read_csv(os.path.join(DATA_DIR, \"interim\", \"income.csv\"))\n",
    "# race_df = pd.read_csv(os.path.join(DATA_DIR, \"interim\", \"race.csv\"))\n",
    "# home_own_rent_df = pd.read_csv(os.path.join(DATA_DIR, \"interim\", \"home_own_rent.csv\"))\n",
    "\n",
    "combined_df = pd.merge(income_df, race_df, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "combined_df = pd.merge(combined_df, home_own_rent_df, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "combined_df = pd.merge(combined_df, educational_attainment_df, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "combined_df = pd.merge(combined_df, age_df, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "combined_df = pd.merge(combined_df, units_in_structure_df, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "combined_df = pd.merge(combined_df, disability_df, how='outer', on=CENSUS_TRACT_COLNAME)\n",
    "\n",
    "for col in combined_df.columns: \n",
    "    if 'percentage_total' in col:\n",
    "        combined_df[col] = combined_df[col].fillna(combined_df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MIN_DICT = {}\n",
    "for col in [column for column in combined_df.columns if 'percentage_total' in column]:\n",
    "    MAX_MIN_DICT[col] = {\n",
    "        'max' : combined_df[col].max(),\n",
    "        'min' : combined_df[col].min()\n",
    "    }\n",
    "\n",
    "rows_w_standardized_values = []\n",
    "for idx, row in combined_df.iterrows():\n",
    "    if row[CENSUS_TRACT_COLNAME] is None:\n",
    "        continue\n",
    "\n",
    "    for col in [column for column in combined_df.columns if 'percentage_total' in column]:\n",
    "\n",
    "        denominator = MAX_MIN_DICT[col]['max'] - MAX_MIN_DICT[col]['min']\n",
    "        standardized_val = (row[col] - MAX_MIN_DICT[col]['min']) / denominator\n",
    "        standardized_colname = col.replace(\"percentage_total\", \"standardized\")\n",
    "        row[standardized_colname] = standardized_val\n",
    "\n",
    "    \n",
    "    rows_w_standardized_values.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m standardized_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(rows_w_standardized_values)\n\u001b[1;32m      2\u001b[0m standardized_df_reduced_columns \u001b[39m=\u001b[39m standardized_df[\n\u001b[1;32m      3\u001b[0m     [CENSUS_TRACT_COLNAME] \u001b[39m+\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m standardized_df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_standardized\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m col]\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m \u001b[39m#standardized_df_reduced_columns.to_csv(os.path.join(DATA_DIR, \"processed\", \"standardized.csv\"), index=False)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eeng415/lib/python3.8/site-packages/pandas/core/frame.py:745\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 745\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    746\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    747\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m         data,\n\u001b[1;32m    749\u001b[0m         columns,\n\u001b[1;32m    750\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    751\u001b[0m         dtype,\n\u001b[1;32m    752\u001b[0m     )\n\u001b[1;32m    753\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    754\u001b[0m         arrays,\n\u001b[1;32m    755\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    758\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    759\u001b[0m     )\n\u001b[1;32m    760\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/eeng415/lib/python3.8/site-packages/pandas/core/internals/construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/eeng415/lib/python3.8/site-packages/pandas/core/internals/construction.py:869\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    867\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m--> 869\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_series_to_arrays(data, columns)\n\u001b[1;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m     \u001b[39m# last ditch effort\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[0;32m~/miniconda3/envs/eeng415/lib/python3.8/site-packages/pandas/core/internals/construction.py:912\u001b[0m, in \u001b[0;36m_list_of_series_to_arrays\u001b[0;34m(data, columns)\u001b[0m\n\u001b[1;32m    910\u001b[0m     indexer \u001b[39m=\u001b[39m indexer_cache[\u001b[39mid\u001b[39m(index)]\n\u001b[1;32m    911\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 912\u001b[0m     indexer \u001b[39m=\u001b[39m indexer_cache[\u001b[39mid\u001b[39m(index)] \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_indexer(columns)\n\u001b[1;32m    914\u001b[0m values \u001b[39m=\u001b[39m extract_array(s, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    915\u001b[0m aligned_values\u001b[39m.\u001b[39mappend(algorithms\u001b[39m.\u001b[39mtake_nd(values, indexer))\n",
      "File \u001b[0;32m~/miniconda3/envs/eeng415/lib/python3.8/site-packages/pandas/core/indexes/base.py:3905\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3902\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3905\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3907\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3908\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "standardized_df = pd.DataFrame(rows_w_standardized_values)\n",
    "standardized_df_reduced_columns = standardized_df[\n",
    "    [CENSUS_TRACT_COLNAME] + [col for col in standardized_df.columns if \"_standardized\" in col]\n",
    "]\n",
    "#standardized_df_reduced_columns.to_csv(os.path.join(DATA_DIR, \"processed\", \"standardized.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_df_reduced_columns.to_csv(os.path.join(DATA_DIR, \"processed\", \"standardized.csv\"), index=False)\n",
    "standardized_df = pd.read_csv(os.path.join(DATA_DIR, \"processed\", \"standardized.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input_columns = [col for col in standardized_df_reduced_columns.columns if '_standardized' in col]\n",
    "pca_input_df = standardized_df_reduced_columns[pca_input_columns]\n",
    "census_tracts = standardized_df_reduced_columns[CENSUS_TRACT_COLNAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=0.85)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.85)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=0.85)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.85)\n",
    "pca.fit(pca_input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_output_df = pd.DataFrame(pca.transform(pca_input_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_output_df.columns = [f\"x{idx}\" for idx in range(len(pca.components_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>census_tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.225187</td>\n",
       "      <td>-0.149232</td>\n",
       "      <td>0.368477</td>\n",
       "      <td>0.295765</td>\n",
       "      <td>-0.017200</td>\n",
       "      <td>-0.046010</td>\n",
       "      <td>0.216196</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.104189</td>\n",
       "      <td>0.509474</td>\n",
       "      <td>0.165538</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.302083</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>0.244756</td>\n",
       "      <td>0.268733</td>\n",
       "      <td>-0.192988</td>\n",
       "      <td>-0.111020</td>\n",
       "      <td>0.193172</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>-0.124874</td>\n",
       "      <td>0.167984</td>\n",
       "      <td>-0.043474</td>\n",
       "      <td>0.092288</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969652</td>\n",
       "      <td>0.064561</td>\n",
       "      <td>0.062836</td>\n",
       "      <td>0.115468</td>\n",
       "      <td>-0.161904</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>-0.075587</td>\n",
       "      <td>-0.169447</td>\n",
       "      <td>0.097774</td>\n",
       "      <td>0.160711</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>-0.063087</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611850</td>\n",
       "      <td>0.261121</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.079005</td>\n",
       "      <td>-0.083322</td>\n",
       "      <td>0.033510</td>\n",
       "      <td>-0.235503</td>\n",
       "      <td>-0.216684</td>\n",
       "      <td>0.190810</td>\n",
       "      <td>0.158696</td>\n",
       "      <td>-0.247446</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.622973</td>\n",
       "      <td>-0.561071</td>\n",
       "      <td>0.427328</td>\n",
       "      <td>-0.146777</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>-0.040714</td>\n",
       "      <td>0.066930</td>\n",
       "      <td>0.076440</td>\n",
       "      <td>0.219344</td>\n",
       "      <td>0.108046</td>\n",
       "      <td>-0.067912</td>\n",
       "      <td>-0.105341</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.121072</td>\n",
       "      <td>-0.407953</td>\n",
       "      <td>0.076673</td>\n",
       "      <td>-0.056382</td>\n",
       "      <td>-0.120624</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>-0.014072</td>\n",
       "      <td>-0.021790</td>\n",
       "      <td>-0.019763</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0.052439</td>\n",
       "      <td>-0.306938</td>\n",
       "      <td>0.040640</td>\n",
       "      <td>-0.051133</td>\n",
       "      <td>-0.082369</td>\n",
       "      <td>0.042198</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.015917</td>\n",
       "      <td>-0.020361</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0.109254</td>\n",
       "      <td>-0.390559</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>-0.055478</td>\n",
       "      <td>-0.114036</td>\n",
       "      <td>0.054377</td>\n",
       "      <td>-0.005367</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>-0.014051</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>-0.019866</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0.274948</td>\n",
       "      <td>-0.634429</td>\n",
       "      <td>0.157460</td>\n",
       "      <td>-0.068150</td>\n",
       "      <td>-0.206391</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>-0.014351</td>\n",
       "      <td>-0.034957</td>\n",
       "      <td>-0.018421</td>\n",
       "      <td>0.031136</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>-0.088733</td>\n",
       "      <td>-0.099159</td>\n",
       "      <td>-0.033477</td>\n",
       "      <td>-0.040336</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.013692</td>\n",
       "      <td>-0.003838</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0    1.225187 -0.149232  0.368477  0.295765 -0.017200 -0.046010  0.216196   \n",
       "1    1.302083 -0.001440  0.244756  0.268733 -0.192988 -0.111020  0.193172   \n",
       "2    0.969652  0.064561  0.062836  0.115468 -0.161904  0.033649 -0.075587   \n",
       "3    0.611850  0.261121 -0.000724  0.079005 -0.083322  0.033510 -0.235503   \n",
       "4    0.622973 -0.561071  0.427328 -0.146777  0.022960 -0.040714  0.066930   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "645  0.121072 -0.407953  0.076673 -0.056382 -0.120624  0.056911 -0.005085   \n",
       "646  0.052439 -0.306938  0.040640 -0.051133 -0.082369  0.042198 -0.006720   \n",
       "647  0.109254 -0.390559  0.070469 -0.055478 -0.114036  0.054377 -0.005367   \n",
       "648  0.274948 -0.634429  0.157460 -0.068150 -0.206391  0.089897 -0.001418   \n",
       "649 -0.088733 -0.099159 -0.033477 -0.040336 -0.003682  0.011935 -0.010084   \n",
       "\n",
       "           x7        x8        x9       x10       x11 census_tract  \n",
       "0    0.075602 -0.119034  0.104189  0.509474  0.165538         None  \n",
       "1    0.111338 -0.124874  0.167984 -0.043474  0.092288         None  \n",
       "2   -0.169447  0.097774  0.160711  0.016590 -0.063087         None  \n",
       "3   -0.216684  0.190810  0.158696 -0.247446 -0.038649         None  \n",
       "4    0.076440  0.219344  0.108046 -0.067912 -0.105341         None  \n",
       "..        ...       ...       ...       ...       ...          ...  \n",
       "645  0.019283 -0.014072 -0.021790 -0.019763  0.024556         None  \n",
       "646  0.013653 -0.013948 -0.015917 -0.020361  0.021622         None  \n",
       "647  0.018314 -0.014051 -0.020779 -0.019866  0.024051         None  \n",
       "648  0.031904 -0.014351 -0.034957 -0.018421  0.031136         None  \n",
       "649  0.002074 -0.013692 -0.003838 -0.021592  0.015586         None  \n",
       "\n",
       "[650 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_output_df[CENSUS_TRACT_COLNAME] = None\n",
    "pca_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_output_df.at[0, CENSUS_TRACT_COLNAME] = \"101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, len(census_tracts)):\n",
    "    pca_output_df.at[idx, CENSUS_TRACT_COLNAME] = census_tracts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_output_df[\"vulnerability_index\"] = \\\n",
    "    pca_output_df[\"x0\"] + pca_output_df[\"x1\"] + pca_output_df[\"x2\"] + pca_output_df[\"x3\"] + \\\n",
    "    pca_output_df[\"x4\"] + pca_output_df[\"x5\"] + pca_output_df[\"x6\"] + pca_output_df[\"x7\"] + \\\n",
    "    pca_output_df[\"x8\"] + pca_output_df[\"x9\"] + pca_output_df[\"x10\"] + pca_output_df[\"x11\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_output_df.to_csv(os.path.join(DATA_DIR, \"final\", \"vulnerability_index_unverified.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeng415",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8604efd85267246b5ae95b2c8bfe7ed65ebcf449068d7e624ae32e9b67f234be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
